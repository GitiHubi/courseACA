{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "th {background-color:#55FF33;}\n",
    "td {background-color:#00FFFF;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"01_images/logo.png\">\n",
    "\n",
    "## Lab 02 - Statistical Audit Data Analytics\n",
    "\n",
    "Audit Data Analytics in Python, University of St.Gallen (HSG), January 13th, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab environment of the **\"Audit Data Analytics Course\"** at the University of St. Gallen (HSG) is based on Jupyter Notebooks (https://jupyter.org), which allow to perform a variety of statistical evaluations and data analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"01_images/banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will use Jupyter Notebook to implement and apply an initial **mathematical-statistical audit analysis procedures** namely the Benford's Law analysis. Thereby, we will implement the Benford distribution using the Python Programming language. Furthermore, we will perform the Benford's Law analysis of leading digits derived from the transaction amounts of a given population of financial transactions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 800px; height: auto\" src=\"01_images/benford.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab or send us an email via marco (dot) schreyer (at) unisg (dot) ch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After today's lab, you should be able to:\n",
    "    \n",
    "> 1. Understand how to perform statistical data analysis using **Jupyter** and **Python**;\n",
    "> 2. Use the **Pandas** library to target and analyze a variety of transactional data;\n",
    "> 3. Use the **Matplotlib** library to create custom data visualizations;\n",
    "> 4. Develop initial **more concrete ideas** for possible data analyses within your company or institution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we start let's watch a brief motivational video published in 2017 by **NVIDIA Inc.** as part of their GPU Technology Conference (GTC) on the revolution of data analytics driven be deep neural networks referred to as \"Deep Learning\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# NVIDIA: \"The Deep Learning Revolution\"\n",
    "# YouTubeVideo('Dy0hJWltsyE', width=1024, height=576)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `NumPy`, `Pandas`, `Matplotlib`, `Seaborn`, and a few utility libraries throughout the lab.\n",
    "\n",
    "Let's import the `Pandas` and the `NumPy` libraries accordingly by executing the following `import` statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we import a couple of `Python's` utility libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # allows to create, access and manipulate data directories\n",
    "import datetime as dt # allows for the create of data time stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import a set of `Python's` data access and import libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io # allows to open and access streams of data\n",
    "import zipfile # allows to zip and unzip data\n",
    "import urllib # allows to handle website requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import the `Matplotlib` and `Seaborn` plotting libraries and set the general data visualization parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set global data visualization parameters\n",
    "plt.style.use('seaborn') # set the plotting style\n",
    "plt.rcParams['figure.figsize'] = [5, 3] # set the plot figure size\n",
    "plt.rcParams['figure.dpi']= 150 # set the plotting resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the \"inline plotting\" of visualizations within the current notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create notebook folder structure to store the original data as well as the analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./02_data'): os.makedirs('./02_data')  # create data directory\n",
    "if not os.path.exists('./03_results'): os.makedirs('./03_results')  # create results directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter and suppress potential library warnings, for example due to library enhancements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# set the warning filter flag to ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Download and Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synthetic **PaySim** dataset simulates mobile money transactions based on real transactions extracted from one month of financial logs of a mobile financial service provider implemented in an African country. The original logs were provided by a multinational company that provided mobile financial services. At the time the data was published, the service provider operated in more than 14 countries worldwide.\n",
    "\n",
    "The latest version of the dataset was published at the Kaggle Data Science Competitions website on April 3th, 2017 by the Norwegian University of Science and Technology (NTNU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, the **PaySim** dataset comprises a population of **6.3 million logged transactions**. Each transaction contains **nine different attributes (features)**. The attribute names and their respective semantic meaning is given below:\n",
    "\n",
    ">- `Step:` Denotes the current hour of time. In total 744 hours (30 simulation days).\n",
    ">- `Type:` Denotes the type of the transaction. In total 5 different transaction types.\n",
    ">- `Amount:` Indicates the amount transferred in local currency.\n",
    "\n",
    ">- `NameOrig:` Identifies the (anonymized) ID of the sender who ordered the transaction.\n",
    ">- `OldBalanceOrg:` Denotes the initial balance of the sender's account before the transaction.\n",
    ">- `NewBalanceOrg:` Indicates the new balance of the sender's account after the transaction.\n",
    "\n",
    ">- `NameDest:` Denotes the (anonymized) ID of the recipient of the transaction.\n",
    ">- `OldBalanceOrg:` Denotes the initial account balance of the recipient before the transaction.\n",
    ">- `NewBalanceOrg:` Denotes the new balance of the recipient's account after the transaction has taken place.\n",
    "\n",
    "In addition, each transaction is marked with the following **two additional flags**:\n",
    "\n",
    ">- `isFraud:` Indicates actual \"fraudulent\" transactions.\n",
    ">- `isFlaggedFraud:` Indicates fraudulent transactions detected by the system.\n",
    "\n",
    "Further details of the dataset, as well as the dataset itself, can be obtained via the following publication:\n",
    "\n",
    "*E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016* \n",
    "\n",
    "or the following website on Kaggle: https://www.kaggle.com/ntnu-testimon/paysim1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Download the PaySim Dataset of Financial Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download a partial extract of the previously described data set consisting of **2,770,409 logged transactions** into the notebook. To do this, we first define the path or URL of the transaction data to be imported: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/GitiHubi/courseACA/master/lab01/02_data/transactions.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step we will open an URL open request to read the data from the provided URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will retrieve the ZIP archive of the data from the opened URL request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datazip = zipfile.ZipFile(io.BytesIO(request.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import the PaySim Dataset as Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will extract the `transactions.csv` file contained in the ZIP archive and read it as a Comma Separated Value (CSV) into `Pandas` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and unzip the ZIP archive\n",
    "csv_file = datazip.open('transactions.csv')\n",
    "\n",
    "# read the csv data as pandas dataframe\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the first 10 transactions (rows) of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the last 10 transactions (rows) of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assignment of Unique Transaction Identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unique **transaction identifier** is used within the dataset to uniquely mark individual records in order to uniquely identify them in the further analysis procedure. Such a unique identifies is often comprised of a sequence of values selected so that each row in the dataset has a unique identifying characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate such a unique sequence of transaction identifiers using the following naming convention `ACA_ID_0000001`, `ACA_ID_0000002`,..., `ACA_ID_2770408`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of numeric values 0, 1, 2, ..., N\n",
    "ids = list(range(0, data.shape[0]))\n",
    "\n",
    "# create list of unique transaction identifier\n",
    "keys = ['ACA_ID_' + str(e).zfill(7) for e in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, let's verify the first five created unique transaction identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keys[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that looks like anticipated. Let's now add the unique transaction identifiers to the original dataset we aim to investigate in the following. Thereby, we will add a designated and leading `AUDIT_ID` column to our dataframe using the `insert` statement available in the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, \"AUDIT_ID\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify if the `AUDIT_ID` column including the unique identifier was successfully created by inspecting the first 10 rows of the dataframe containing the transaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's also inspect the last 10 rows of the dataframe containing the transaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, now that we assigned each row in our dataset a unique identifier let's continue with the structural data validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation and Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preparation** defines the cleaning and transformation of raw data prior to the actual processing and analysis. Data preparation is an important step before the actual data analysis to be performed and often involves reformatting data, correcting information, and combining data sets to enrich that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Extraction of \"CASH_OUT\" Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again, in a first step, extract all \"CASH_OUT\" transactions from the dataset. To achieve this we will use the data filter capabilities of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and extraction of cash out transactions\n",
    "transactions_cash_out = data[data[\"type\"] == \"CASH_OUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Formatting of Data Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conduct a simple semantic formatting of the data attributes `isFraud` and `isFlaggedFraud` in order to improve the interpretability of a human auditor. Therefore, let's first review the current formatting by inspecting the first five rows of the transactional dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the `isFraud` attribute encompasses two binary values. The values corresponding to either the value `1` which denotes a fraudulent transaction or the value `0` which denotes a non-fraudulent transaction. In a next step we will reformat those values accordingly in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for fraudulent transations and replace the \"isFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFraud'] == 1, 'isFraud'] = 'yes' # replace the value \"1\" with \"yes\"\n",
    "\n",
    "# filter for non-fraudulent transations and replace the \"isFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFraud'] == 0, 'isFraud'] = 'no' # replace the value \"0\" with \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spot check the performed replacement by the re-inspection of the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply the same reformatting to the `isFlaggedFraud` attribute in the dataset. Remember, the values corresponding to either the value 1 which denotes a transaction flagged as fraudulent or the value 0 which denotes a transaction flagged as non-fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for transations flagged as fraudulent and replace the \"isFlaggedFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFlaggedFraud'] == 1, 'isFlaggedFraud'] = 'yes' # replace the value \"1\" with \"yes\"\n",
    "\n",
    "# filter for transations flagged as non-fraudulent and replace the \"isFlaggedFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFlaggedFraud'] == 0, 'isFlaggedFraud'] = 'no' # replace the value \"0\" with \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again spot check the performed replacement by the re-inspection of the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mathematical-Statistical Audit Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 800px; height: auto\" src=\"01_images/analytics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Analytics: Benford-Newcomb Analysis of the First Leading Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a first step,  let's create a Benford distribution reference table for each possible single leading digit value. Therefore, we will derive the probabilities $p(d)$ according to Benford for the individual leading digits as defined by: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(d) = \\log_{10}(d+1) - \\log_{10}(d);$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $d \\in [0, 1, ...,9]$ denotes an actual leading digit value. \n",
    "\n",
    "Source: „The Law of Anomalous Numbers“, Benford F., Proceedings of the American Philosophical Society, Vol. 78, 1938, USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Create the Benford-Newcomb Probability Reference Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a `Pandas` dataframe that contains all the individual leading digits: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table = pd.DataFrame({\"digit_1\": range(1, 10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, we will derive the probability of observing a particular leading digit according to Benford and add the probability accordingly to the dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table[\"benford\"] = (np.log10(benford_table[\"digit_1\"] + 1)) - np.log10(benford_table[\"digit_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect our created Benford probability reference table of the leading transaction amount digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, let's also compute and add confidence intervals of $\\sigma=3$ standard deviations to the created Benford probability reference table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the total number of cash out transactions\n",
    "n = transactions_cash_out.shape[0]\n",
    "\n",
    "# determine the upper bound of the three sigma confidence interval\n",
    "benford_table[\"benford_upp\"] = benford_table[\"benford\"] + 1.96 * np.sqrt((benford_table[\"benford\"] * (1 - benford_table[\"benford\"]))/n) \n",
    "\n",
    "# determine the lower bound of the three sigma confidence interval\n",
    "benford_table[\"benford_low\"] = benford_table[\"benford\"] - 1.96 * np.sqrt((benford_table[\"benford\"] * (1 - benford_table[\"benford\"]))/n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, let's verify the added lower and upper bound of the confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's also visualize the expected first leading digit probability according to Benford:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the plot \n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# plot the benford probabilities \n",
    "plt.plot(benford_table[\"digit_1\"], benford_table[\"benford\"], color=\"red\")\n",
    "\n",
    "# plot the benford probability density\n",
    "plt.fill_between(benford_table[\"digit_1\"], benford_table[\"benford\"], color=\"red\", alpha=0.1)\n",
    "\n",
    "# add the axis labels\n",
    "plt.ylabel(\"[Probability]\", fontsize=12)\n",
    "plt.xlabel(\"[Leading Digit]\", fontsize=12)\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# add the plot title\n",
    "plt.title(\"Benford-Newcomb Distribution - First Leading Digit\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Determine the Actual Probabilities of the Transaction Amounts Leading Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have prepared our reference table including the confidence intervals let's focus on the leading digits of the \"CASH_OUT\" transactions. Therefore, we will extract the leading digit of each transaction and add it as a separate column to dataframe of all transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out[\"digit_1\"] = transactions_cash_out[\"amount\"].astype(str).str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the extracted leading digits based on the first 10 rows of the transactional dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out[[\"amount\", \"digit_1\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, let's determine the actual probability of observing a specific leading digit in the dataset of \"CASH_OUT\" transactions. Therefore, we will derive a list of all observable leading digits in the dataset:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis = pd.DataFrame({\"digit_1\": transactions_cash_out[\"digit_1\"].value_counts().index.astype(np.int64).tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we count the number of times a particular leading digit is evident in the \"CASH_OUT\" transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis[\"count\"] = transactions_cash_out[\"digit_1\"].value_counts().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the probability of observing a particular leading digit in the \"CASH_OUT\" transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis[\"probability\"] = benford_analysis[\"count\"] / transactions_cash_out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now inspect and verify the derived probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Benford-Newcomb Analysis of the Transaction Amounts Leading Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude the Benford analysis let's merge the initially created reference table of Benford probabilities with the actual observed probability of observing a particular leading digit. To achieve this we will use the `merge` function available in the `Pandas` library: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_single_leding_digit = benford_table.merge(benford_analysis, on=\"digit_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finally in the position to compare both probabilities (the expected probability according to Benford-Newcomb and the observed probability in the dataset) and detect potential deviations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_single_leding_digit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, let's also visually inspect the probability distribution expected by Benford-Newcomb and the observed probabilities available in the dataset of \"CASH_OUT\" transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the plot \n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# plot the benford probabilities \n",
    "plt.plot(analysis_result_single_leding_digit[\"digit_1\"], analysis_result_single_leding_digit[\"benford\"], color=\"red\")\n",
    "\n",
    "# plot the actual distribution of the first digit\n",
    "plt.bar(analysis_result_single_leding_digit[\"digit_1\"], analysis_result_single_leding_digit[\"probability\"], color=\"green\")\n",
    "\n",
    "# plot the benford probability density\n",
    "plt.fill_between(np.arange(1.0, 10.0, 1.0), analysis_result_single_leding_digit[\"benford\"], color=\"red\", alpha=0.1)\n",
    "\n",
    "# add the axis labels\n",
    "plt.ylabel(\"[Probability]\", fontsize=12)\n",
    "plt.xlabel(\"[Leading Digit]\", fontsize=12)\n",
    "\n",
    "# format the x-tick labels\n",
    "plt.xticks(range(1,10), range(1,10))\n",
    "\n",
    "# add the plot title\n",
    "plt.title(\"Benford-Newcomb Analysis - First Leading Digit\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Analytics: Benford-Newcomb Analysis of the First and Second Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Create the Benford-Newcomb Probability Reference Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start again by creating a `Pandas` dataframe that contains all possible combinations of the first and second leading transaction amount digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table = pd.DataFrame({\"digit_2\": range(1, 100)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as before, we will derive the probability of observing a particular leading digit combination according to\n",
    "Benford. Afterwards, we will add the obtained probabilities to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table[\"benford\"] = (np.log10(benford_table[\"digit_2\"] + 1)) - np.log10(benford_table[\"digit_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now inspect the distinct rows of the created Benford probability reference table. The table contains all possible two leading digit combinations as well as their corresponding probability of occurrence according to Benford:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, let’s also compute and add confidence intervals of σ = 3 standard deviations. We will add the upper and lower bound of the determined confidence intervals to the created reference table of Benford probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the total number of cash out transactions\n",
    "n = transactions_cash_out.shape[0]\n",
    "\n",
    "# determine the upper bound of the three sigma confidence interval\n",
    "benford_table[\"benford_upp\"] = benford_table[\"benford\"] + 1.96 * np.sqrt((benford_table[\"benford\"] * (1 - benford_table[\"benford\"]))/n) \n",
    "\n",
    "# determine the lower bound of the three sigma confidence interval\n",
    "benford_table[\"benford_low\"] = benford_table[\"benford\"] - 1.96 * np.sqrt((benford_table[\"benford\"] * (1 - benford_table[\"benford\"]))/n) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, let’s verify the added lower and upper bound of the confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s also visualize the expected first leading digit probability according to Benford:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the plot \n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# plot the benford probabilities \n",
    "plt.plot(benford_table[\"digit_2\"], benford_table[\"benford\"], color=\"red\")\n",
    "\n",
    "# plot the benford probability density\n",
    "plt.fill_between(benford_table[\"digit_2\"], benford_table[\"benford\"], color=\"red\", alpha=0.1)\n",
    "\n",
    "# add the axis labels\n",
    "plt.ylabel(\"[Probability]\", fontsize=12)\n",
    "plt.xlabel(\"[Leading Digits]\", fontsize=12)\n",
    "\n",
    "# format the x-tick labels\n",
    "plt.xticks(range(10, 100), range(10, 100))\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# format the x-axis limits\n",
    "plt.xlim(10, 99)\n",
    "\n",
    "# format the y-axis limits\n",
    "plt.ylim(0.0, 0.05)\n",
    "\n",
    "# add the plot title\n",
    "plt.title(\"Benford-Newcomb Distribution - First and Second Leading Digit\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Determine the Actual Probabilities of the First and Second Leading Transaction Amounts Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have prepared our reference table including the confidence intervals let’s focus on the two leading digits of the “CASH_OUT” transactions. Therefore, we will extract both leading digit of each transaction and add it as a separate column to dataframe of all transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out[\"digit_2\"] = transactions_cash_out[\"amount\"].astype(str).str[0] + transactions_cash_out[\"amount\"].astype(str).str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s verify the extracted leading digits based on the first 10 rows of the transactional dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out[[\"amount\", \"digit_2\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, let’s determine the actual probability of observing a specific combination of leading digits in the dataset of “CASH_OUT” transactions. Therefore, we will derive a list of all observable leading digits in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis = pd.DataFrame({\"digit_2\": transactions_cash_out[\"digit_2\"].value_counts().index.map(lambda t: t.replace('.', '')).astype(np.int64).tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we count the number of times a particular combination of leading digits is evident in the “CASH_OUT” transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis[\"count\"] = transactions_cash_out[\"digit_2\"].value_counts().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the probability of observing a particular combination of leading digits in the “CASH_OUT” transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis[\"probability\"] = transactions_cash_out[\"digit_2\"].value_counts(normalize=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now inspect and verify the derived probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Benford-Newcomb Analysis of the First and Second Leading Transaction Amounts Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude the Benford-Newcomb analysis let’s merge the initially created reference table of Benford-Newcomb probabilities with the actual observed probability of observing a particular combination of leading digits. To achieve this we will again use the merge function available in the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_double_leading_digits = benford_table.merge(benford_analysis, on=\"digit_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finally in the position to compare both probabilities (the expected probability according to Benford-Newcomb and the observed probability in the dataset) and detect potential deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_double_leading_digits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, let’s again also visually inspect the probability distribution expected by Benford-Newcomb and the observed probabilities available in the dataset of “CASH_OUT” transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the plot \n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# plot the benford probabilities \n",
    "plt.plot(analysis_result_double_leading_digits[\"digit_2\"], analysis_result_double_leading_digits[\"benford\"], color=\"red\")\n",
    "\n",
    "# plot the actual distribution of the first digit\n",
    "plt.bar(analysis_result_double_leading_digits[\"digit_2\"], analysis_result_double_leading_digits[\"probability\"], color=\"green\")\n",
    "\n",
    "# plot the benford probability density\n",
    "plt.fill_between(analysis_result_double_leading_digits[\"digit_2\"], analysis_result_double_leading_digits[\"benford\"], color=\"red\", alpha=0.1)\n",
    "\n",
    "# add the axis labels\n",
    "plt.ylabel(\"[Probability]\", fontsize=12)\n",
    "plt.xlabel(\"[Leading Digits]\", fontsize=12)\n",
    "\n",
    "# format the x-tick labels\n",
    "plt.xticks(range(10, 100), range(10, 100))\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# format the x-axis limits\n",
    "plt.xlim(9.0, 100.0)\n",
    "\n",
    "# format the y-axis limits\n",
    "plt.ylim(0.0, 0.05)\n",
    "\n",
    "# add the plot title\n",
    "plt.title(\"Benford-Newcomb Distribution - First and Second Leading Digit\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Analytics: Investigation of Significant Probability Deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next step, let's investigate the combination of leading transaction amount digits that correspond to the largest deviation when compared to Benford-Newcomb distribution. Therefore, we compute the the delta of the Benford-Newcomb probability and the actual observable probability of each leading digit combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_double_leading_digits[\"delta\"] = np.abs(analysis_result_double_leading_digits[\"benford\"] -  analysis_result_double_leading_digits[\"probability\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are able to determine the combinations of leading digits probabilities that show a significant deviation. To achieve this, we will sort the dataframe accordingly using the `sort_values` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_result_double_leading_digits.sort_values(by=['delta'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we will visualize the obtained deviation accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the plot \n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# plot the actual distribution of the first digit\n",
    "plt.bar(analysis_result_double_leading_digits[\"digit_2\"], analysis_result_double_leading_digits[\"delta\"], color=\"darkviolet\")\n",
    "\n",
    "# add the axis labels\n",
    "plt.ylabel(\"[Probability Deviation]\", fontsize=12)\n",
    "plt.xlabel(\"[Leading Digits]\", fontsize=12)\n",
    "\n",
    "# format the x-tick labels\n",
    "plt.xticks(range(10, 100), range(10, 100))\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# format the x-axis limits\n",
    "plt.xlim(9.5, 100.0)\n",
    "\n",
    "# format the y-axis limits\n",
    "plt.ylim(0.0, 0.01)\n",
    "\n",
    "# add the plot title\n",
    "plt.title(\"Benford-Newcomb Deviation Analysis - First and Second Leading Digit\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the deviation analysis shown above, a significant difference for the digit combinations ranging from \"16\" to \"22\" can be observed. Thereby, the digit combination \"18\" corresponds to the highest digit combination. \n",
    "\n",
    "In the following, we will therefore extract all \"CASH_OUT\" transactions that exhibit the digit combination of \"18\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set digit combination\n",
    "digit = \"18\"\n",
    "\n",
    "# filter corresponding cash out transactions\n",
    "transactions_cash_out_18 = transactions_cash_out[transactions_cash_out[\"digit_2\"] == digit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's review the extracted transactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_18.sort_values(by=['amount'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect in detail the amounts of the extracted \"CASH_OUT\" transactions that exhibit the digit combination of \"18\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# scatter plot of cash out transactions that exhibit a leading digit amount equal to 18\n",
    "plt.scatter(transactions_cash_out_18.index, transactions_cash_out_18[\"amount\"], color=\"darkviolet\")\n",
    "\n",
    "# plot unusual amount threshold\n",
    "plt.axhline(y=1750000, color=\"r\", linestyle=\"--\", label=\"threshold\")\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Amount]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# hide x-ticks\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Benford-Newcomb Deviation Analysis - First and Second Leading Digit: 18\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems that the is an unusual transaction amount pattern evident.\n",
    "\n",
    "Let's apply a filter to determine all \"CASH_OUT\" transactions that correspond to a total transaction volume **equal or exceeding an amount value of 1,75 Mio.** in local currency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount threshold\n",
    "threshold = 1750000\n",
    "\n",
    "# filter the cash-out transactions according to the amount threshold \n",
    "transactions_cash_out_18_large = transactions_cash_out_18[transactions_cash_out_18[\"amount\"] >= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a sample based review of the extracted transactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_18_large.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's extract the filtered transactions into an excel spreadsheet for a further sample based testing by the audit team. Therefore, we will in a first step create a time stamp of the data extract for audit trail purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we extract the filtered transactions to excel to the local filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the filename of the excel spreadsheet\n",
    "filename = str(timestamp) + \" - ACA_001_benford_newcomb_18.xlsx\"\n",
    "\n",
    "# specify the target data directory of the excel spreadsheet\n",
    "data_directory = os.path.join('./03_results', filename)\n",
    "\n",
    "# extract the filtered transactions to excel\n",
    "transactions_cash_out_18_large.to_excel(data_directory, header=True, index=False, sheet_name=\"Business_Partner_Amounts\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Assignements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend you to try the following exercises as part of the lab:\n",
    "\n",
    "**1. Analyze the \"CASH-OUT\" transactions that have the leading digit combination 15 and 16.**\n",
    "\n",
    "> Analyze the approx. 2.2 million \"CASH-OUT\" transactions extracted during data validation with regard to the leading digit combinations '15' and '16'. For this, please follow the procedure presented in section 4.3. of the notebook. Extract the individual transactions to a separate excel or csv file for a downstream sample testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE SOLUTION HERE\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Analyze the leading digit combinations of the \"TRANSFER\" transactions according to Benford-Newcomp.**\n",
    "\n",
    "> Analyze the transaction amounts in the data validation extracted 532'909 \"TRANSFER\" transactions according to the Benford-Newcomb law. In doing so, please follow the procedure presented in sections 4.1 and 4.2 of the notebook. Extract the individual transactions that correspond to deviations of the Benford-Newcomb law to a separate excel or csv file for a downstream sample testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE SOLUTION HERE\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, a step-by-step introduction to mathematical-statistical audit data analytics was presented. In particular, the analysis of the leading digits of a population of financial transactions according to the Benford-Newcomb Law. The analysis procedure presented in this lab can be viewed as starting point for more tailored and complex analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to execute the content of your lab outside of the Jupyter notebook environment, e.g. on a compute node or a server. The cell below converts the lab notebook into a standalone and executable python script. Pls. note that to convert the notebook, you need to install Python's `NBConvert` library and its extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the nbconvert library (uncomment the following statements if needed)\n",
    "# !pip3 install nbconvert\n",
    "# !pip3 install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert the Jupyter notebook into a plain Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script aca_lab02.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "927px",
    "left": "28px",
    "top": "111px",
    "width": "203px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
