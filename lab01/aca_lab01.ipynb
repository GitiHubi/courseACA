{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "th {background-color:#55FF33;}\n",
    "td {background-color:#00FFFF;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"01_images/logo.png\">\n",
    "\n",
    "## Lab 01 - Rule-Based Audit Data Analytics\n",
    "\n",
    "Audit Data Analytics in Python, University of St.Gallen (HSG), January 13th, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab environment of the **\"Audit Data Analytics Course\"** at the University of St. Gallen (HSG) is based on Jupyter Notebooks (https://jupyter.org), which allow to perform a variety of statistical evaluations and data analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 900px; height: auto\" src=\"01_images/banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lab, we learned about the basic functionality of Jupyter Notebooks. In this lab, we will use Jupyter Notebook to delve into some elements of the revisited data analysis process. The main goal of this lab here is to exemplarily perform the steps of a data import, a data validation as well as a data analysis based on a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 800px; height: auto\" src=\"01_images/process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, pls. don't hesitate to ask all your questions either during the lab or send us an email via marco (dot) schreyer (at) unisg (dot) ch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After today's lab, you should be able to:\n",
    "\n",
    "> 1. Understand how to perform auditing data analysis using **Jupyter** and **Python**.\n",
    "> 2. Use the **Pandas** library to analyze a variety of transactional data in a targeted manner.\n",
    "> 3. Use the **Matplotlib** library to create custom data visualizations.\n",
    "> 4. Develop initial **more concrete ideas** for possible data analyses within your company or institution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we start let's watch a brief motivational video published by the **American Institute of Certified Public Accountants (AICPA)** in 2019 on the application of Jupyter Notebooks and the Python Programming language in Financial Statement Audits: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# AICPA: Upgrade the Financial Statement Audit with Audit Data Analytics\n",
    "# YouTubeVideo('kHY-Ioq_InA', width=1024, height=576)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In analogy to our introductory lab, it is first necessary again to import some Python libraries that allow us to perform data acquisition, data analysis and data visualization. In this lab, we will specifically use the following three libraries (1) **Pandas** (https://pandas.pydata.org), (2) **NumPy** (https://numpy.org) and (3) **Matplotlib** (https://matplotlib.org) in the context of data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the `Pandas` and the `NumPy` libraries accordingly by executing the following `import` statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we import a couple of `Python's` utility libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # allows to create, access and manipulate data directories\n",
    "import datetime as dt # allows for the create of data time stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import a set of `Python's` data access and import libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io # allows to open and access streams of data\n",
    "import zipfile # allows to zip and unzip data\n",
    "import urllib # allows to handle website requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import the `Matplotlib` and `Seaborn` plotting libraries and set the general data visualization parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# set global data visualization parameters\n",
    "plt.style.use('seaborn') # set the plotting style\n",
    "plt.rcParams['figure.figsize'] = [5, 3] # set the plot figure size\n",
    "plt.rcParams['figure.dpi']= 150 # set the plotting resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable the \"inline plotting\" of visualizations within the current notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create notebook folder structure to store the original data as well as the analysis results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./02_data'): os.makedirs('./02_data')  # create data directory\n",
    "if not os.path.exists('./03_results'): os.makedirs('./03_results')  # create results directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter and suppress potential library warnings, for example due to library enhancements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# set the warning filter flag to ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Download and Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synthetic **PaySim** dataset simulates mobile money transactions based on real transactions extracted from one month of financial logs of a mobile financial service provider implemented in an African country. The original logs were provided by a multinational company that provided mobile financial services. At the time the data was published, the service provider operated in more than 14 countries worldwide.\n",
    "\n",
    "The latest version of the dataset was published at the Kaggle Data Science Competitions website on April 3th, 2017 by the Norwegian University of Science and Technology (NTNU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, the **PaySim** dataset comprises a population of **6.3 million logged transactions**. Each transaction contains **nine different attributes (features)**. The attribute names and their respective semantic meaning is given below:\n",
    "\n",
    ">- `Step:` Denotes the current hour of time. In total 744 hours (30 simulation days).\n",
    ">- `Type:` Denotes the type of the transaction. In total 5 different transaction types.\n",
    ">- `Amount:` Indicates the amount transferred in local currency.\n",
    "\n",
    ">- `NameOrig:` Identifies the (anonymized) ID of the sender who ordered the transaction.\n",
    ">- `OldBalanceOrg:` Denotes the initial balance of the sender's account before the transaction.\n",
    ">- `NewBalanceOrg:` Indicates the new balance of the sender's account after the transaction.\n",
    "\n",
    ">- `NameDest:` Denotes the (anonymized) ID of the recipient of the transaction.\n",
    ">- `OldBalanceOrg:` Denotes the initial account balance of the recipient before the transaction.\n",
    ">- `NewBalanceOrg:` Denotes the new balance of the recipient's account after the transaction has taken place.\n",
    "\n",
    "In addition, each transaction is marked with the following **two additional flags**:\n",
    "\n",
    ">- `isFraud:` Indicates actual \"fraudulent\" transactions.\n",
    ">- `isFlaggedFraud:` Indicates fraudulent transactions detected by the system.\n",
    "\n",
    "Further details of the dataset, as well as the dataset itself, can be obtained via the following publication:\n",
    "\n",
    "*E. A. Lopez-Rojas , A. Elmir, and S. Axelsson. \"PaySim: A financial mobile money simulator for fraud detection\". In: The 28th European Modeling and Simulation Symposium-EMSS, Larnaca, Cyprus. 2016* \n",
    "\n",
    "or the following website on Kaggle: https://www.kaggle.com/ntnu-testimon/paysim1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Download the PaySim Dataset of Financial Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's download a partial extract of the previously described data set consisting of **2,770,409 logged transactions** into the notebook. To do this, we first define the path or URL of the transaction data to be imported: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/GitiHubi/courseACA/master/lab01/02_data/transactions.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step we will open an URL open request to read the data from the provided URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will retrieve the ZIP archive of the data from the opened URL request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datazip = zipfile.ZipFile(io.BytesIO(request.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Import the PaySim Dataset as Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will extract the `transactions.csv` file contained in the ZIP archive and read it as a Comma Separated Value (CSV) into `Pandas` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and unzip the ZIP archive\n",
    "csv_file = datazip.open('transactions.csv')\n",
    "\n",
    "# read the csv data as pandas dataframe\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the first 10 transactions (rows) of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the last 10 transactions (rows) of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of **data validation** is a crucial element in the run-up to any audit data analysis process. \n",
    "\n",
    "It creates confidence in the completeness and accuracy of the data being analyzed. The **structural** and **semantic** data validation of the data to be analyzed is necessary to mitigate any analysis errors. The lack of initial validation of the data being analyzed creates an increased risk of erroneous analysis results and the conclusions and decisions derived from them. Let's now start an exemplary data validation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Assignment of Unique Transaction Identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unique **transaction identifier** is used within the dataset to uniquely mark individual records in order to uniquely identify them in the further analysis procedure. Such a unique identifies is often comprised of a sequence of values selected so that each row in the dataset has a unique identifying characteristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate such a unique sequence of transaction identifiers using the following naming convention `ACA_ID_0000001`, `ACA_ID_0000002`,..., `ACA_ID_2770408`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of numeric values 0, 1, 2, ..., N\n",
    "ids = list(range(0, data.shape[0]))\n",
    "\n",
    "# create list of unique transaction identifier\n",
    "keys = ['ACA_ID_' + str(e).zfill(7) for e in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequently, let's verify the first five created unique transaction identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keys[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that looks like anticipated. Let's now add the unique transaction identifiers to the original dataset we aim to investigate in the following. Thereby, we will add a designated and leading `AUDIT_ID` column to our dataframe using the `insert` statement available in the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, \"AUDIT_ID\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify if the `AUDIT_ID` column including the unique identifier was successfully created by inspecting the first 10 rows of the dataframe containing the transaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's also inspect the last 10 rows of the dataframe containing the transaction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, now that we assigned each row in our dataset a unique identifier let's continue with the structural data validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Structural Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **structural data validation** validates whether the received data show technical inconsistencies (\"gaps\") between the expected data population and the actually received data population, e.g. missing records or formatting errors. The primary objective here is to ensure the technical completeness and integrity of the received data.\n",
    "\n",
    "Let's now conduct a simple structural validation of the retrieved transactional data. Let's therefore, in a first step, validate the dimensionality of the data. Thereby, we start with the verification of the number of contained transactions (rows) using the `shape` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's validate the number of attributes (columns) contained in the transactional data using again the `shape` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally. let's also verify the data types of the distinct data attributes. Thereby, the distinct data types are defined according to the following specifications:\n",
    "\n",
    ">- `int64`:  denotes full `integer` number values.\n",
    ">- `object`:  denotes text or mixed numeric and non-numeric values.\n",
    ">- `float64`: denotes floating point `float` number values.\n",
    "\n",
    "The data types of the distinct attributes can be obtained using the `dtypes` function of the `Pandas`library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Semantic Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **semantic data validation** validates whether the received data shows semantic inconsistencies (\"discrepancies\") between the expected data population and the actually received data population, e.g. unusual or incorrect field characteristics. The primary objective here is to ensure the semantic completeness and consistency of the received data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Semantic Validation of Individual Attribute Value Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now conduct a simple semantic validation of the retrieved transactional data. Let's therefore, in a first step, validate the values of the individual attributes. Thereby, we start with the verification of unique attribute values per individual attribute using the `nunique` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's inspect the distinct value distributions of the individual numerical attributes using the `describe` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at a brief example of determining the value counts of a particular data attribute using the `value_counts` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the obtained value counts to gain a more intuitive understanding of the count distribution using the plotting capabilities of the `Matplotlib` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot a histogram of the value counts\n",
    "data[\"type\"].value_counts().plot(ax=ax, kind='bar', color=\"green\", alpha=0.8)\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Count]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Type]\", fontsize=12)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of Transaction Types\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Semantic Validation of Combined Attribute Value Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step let's conduct a simple semantic validation of a combination of attributes contained in the retrieved transactional data. Thereby, we aim to investigate the number of distinct values of the combined data attributes `type` and `isFraud` of transactional data. This can be achieved using the `pivot_table` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data, values=\"step\", index=[\"type\"], columns=[\"isFraud\"], aggfunc=np.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again visualize the obtained value counts to gain a more intuitive understanding of the combined count distribution using the plotting capabilities of the `Matplotlib` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create pivot table of \"type\" and \"isFraud\" field\n",
    "pivot = pd.pivot_table(data, values=\"step\", index=[\"type\"], columns=[\"isFraud\"], aggfunc=np.size)\n",
    "\n",
    "# plot the pivot table as seaborn heatmap\n",
    "sns.heatmap(pivot, square=True, annot=True, fmt='d', cbar=False, cmap='BuGn_r')\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Count]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Type]\", fontsize=12)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of Transaction Types\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Semantic Validation of Individual Transaction Type Attribute Value Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will conduct a semantic validation of the amount field of transactions of type **\"CASH_OUT\"**. Let's therefore in a first step extract all \"CASH_OUT\" transactions from the dataset. To achieve this we will use the data filter capabilities of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and extraction of cash out transactions\n",
    "transactions_cash_out = data[data[\"type\"] == \"CASH_OUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify the completeness of the filtered **\"CASH_OUT\"** transactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will visualize the posting amounts of each filtered **\"CASH_OUT\"** transactions vs. its corresponding process step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the scatter plot of all cash out posting amounts\n",
    "plt.scatter(transactions_cash_out[\"step\"], transactions_cash_out[\"amount\"], color=\"green\", alpha=0.5, label=\"Cash-Out\")\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Amount]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Step]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# add plot legend\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of `Cash-Out` Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now in a second step extract all **\"TRANSFER\"** transactions from the dataset. To achieve this we will use the data filter capabilities of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter and extraction of transfer transactions\n",
    "transactions_transfer = data[data[\"type\"] == \"TRANSFER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify the completeness of the filtered **\"TRANSFER\"** transactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_transfer.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will again visualize the posting amounts of each filtered **\"CASH_OUT** transactions vs. its corresponding process step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the scatter plot of all cash out posting amounts\n",
    "plt.scatter(transactions_transfer[\"step\"], transactions_transfer[\"amount\"], color=\"green\", alpha=0.5, label=\"Transfer\")\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Amount]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Step]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# add plot legend\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of `Transfer` Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation and Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preparation** defines the cleaning and transformation of raw data prior to the actual processing and analysis. Data preparation is an important step before the actual data analysis to be performed and often involves reformatting data, correcting information, and combining data sets to enrich that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Formatting of Data Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conduct a simple semantic formatting of the data attributes `isFraud` and `isFlaggedFraud` in order to improve the interpretability of a human auditor. Therefore, let's first review the current formatting by inspecting the first five rows of the transactional dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the `isFraud` attribute encompasses two binary values. The values corresponding to either the value `1` which denotes a fraudulent transaction or the value `0` which denotes a non-fraudulent transaction. In a next step we will reformat those values accordingly in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for fraudulent transations and replace the \"isFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFraud'] == 1, 'isFraud'] = 'yes' # replace the value \"1\" with \"yes\"\n",
    "\n",
    "# filter for non-fraudulent transations and replace the \"isFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFraud'] == 0, 'isFraud'] = 'no' # replace the value \"0\" with \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spot check the performed replacement by the re-inspection of the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply the same reformatting to the `isFlaggedFraud` attribute in the dataset. Remember, the values corresponding to either the value 1 which denotes a transaction flagged as fraudulent or the value 0 which denotes a transaction flagged as non-fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for transations flagged as fraudulent and replace the \"isFlaggedFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFlaggedFraud'] == 1]['isFlaggedFraud'] = 'yes' # replace the value \"1\" with \"yes\"\n",
    "\n",
    "# filter for transations flagged as non-fraudulent and replace the \"isFlaggedFraud\" flag value\n",
    "transactions_cash_out.loc[transactions_cash_out['isFlaggedFraud'] == 0]['isFlaggedFraud'] = 'no' # replace the value \"0\" with \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again spot check the performed replacement by the re-inspection of the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rule-Based ('Red-Flag') Audit Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 800px; height: auto\" src=\"01_images/analytics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Analytics: Identification of Unusual High Round Payment Amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <table class=\"table table-bordered table-striped table-hover\">\n",
    "    <col width=\"150\">\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">ID: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">ACA 001</p></td>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Name: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Unusual High Round Payment Amounts</p></td>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Risk: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Unusual high round amount payments pose an increased risk of high financial losses.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Hypothesis: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Outgoing value should follow a general distributional pattern.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Data: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Population of the 2,237,500 \"cash-out\" transactions that comprise the 'PaySim' dataset.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Analytics: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Identification of all cash-out transactions with a transaction amount higher or equal to 10 million in local currency. Extraction of the relevant cash-out transactions from the 'PaySim' dataset for a sample based case-by-case review.</p></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to conduct the analysis, let's again visually inspect the individual payment amounts of the entire population of 2,237,500 'CASH_OUT' transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the scatter plot of all cash out posting amounts\n",
    "plt.scatter(transactions_cash_out[\"step\"], transactions_cash_out[\"amount\"], color=\"green\", alpha=0.5, label=\"Cash-Out\")\n",
    "\n",
    "# plot unusual amount threshold\n",
    "plt.axhline(y=9900000, color=\"r\", linestyle=\"--\", label=\"threshold\")\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Amount]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Step]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# add plot legend\n",
    "plt.legend(loc=\"lower right\", frameon=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of `Cash-Out` Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization it appears that there is an unusual pattern evident around the transaction amounts higher or equal to 10 Mio. in local currency. Let's therefore in a next step also visually inspect the distribution of all payments that exhibit an amounts higher than 1 Mio. in local currency: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the scatter plot of all cash out posting amounts\n",
    "plt.hist(transactions_cash_out[transactions_cash_out[\"amount\"] > 1000000][\"amount\"], color=\"green\", alpha=0.5, label=\"Cash-Out\", bins=40)\n",
    "\n",
    "# plot unusual amount threshold\n",
    "plt.axvline(x=9800000, color=\"r\", linestyle=\"--\", label=\"threshold\")\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Transaction Count]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Amount]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# add plot legend\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of `Cash-Out` Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, from the distribution plot it seems that there is indeed an unexpected high number of transactions evident around the transaction amount of 10 Mio. in local currency. Let's therefore apply a filter for all \"CASH_OUT\" transactions that are **equal or exceed an amount value of 10 Mio.** in local currency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount threshold\n",
    "threshold = 10000000\n",
    "\n",
    "# filter the transactions according to the amount threshold \n",
    "transactions_cash_out_high_value = transactions_cash_out[transactions_cash_out[\"amount\"] >= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the total number of filtered \"CASH_OUT\" transactions that exhibit an unusual high amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_high_value.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visually inspect the first 10 transactions that exhibit an unusual high amount value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_high_value.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's extract the filtered transactions into an excel spreadsheet for a further sample based testing by the audit team. Therefore, we will in a first step create a time stamp of the data extract for audit trail purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we extract the filtered transactions to excel to the local filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the filename of the excel spreadsheet\n",
    "filename = str(timestamp) + \" - ACA_001_analysis_result_unusual_high_amounts.xlsx\"\n",
    "\n",
    "# specify the target data directory of the excel spreadsheet\n",
    "data_directory = os.path.join('./03_results', filename)\n",
    "\n",
    "# extract the filtered transactions to excel\n",
    "transactions_cash_out_high_value.to_excel(data_directory, header=True, index=False, sheet_name=\"High_Round_Amounts\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing our analysis let's remove the already extracted **ACA_001** Analytics transactions from the entire population of transactions in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_filtered = transactions_cash_out[transactions_cash_out[\"amount\"] < threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Analytics: Identification of Unusual High Payment Amounts between Business Partners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <table class=\"table table-bordered table-striped table-hover\">\n",
    "    <col width=\"150\">\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">ID: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">ACA 002</p></td>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Name: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Unusual High Payments Between Business Partners</p></td>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Risk: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Unusual high payments between business partners pose an increased risk of high financial losses.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Hypothesis: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Outgoing value should follow a general distributional pattern.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Data: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Population of the 2,237,500 \"cash-out\" transactions that comprise the 'PaySim' dataset.</p></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b align=\"left\" style=\"font-size:16px\">Analytics: </b></td>\n",
    "            <td><p align=\"left\" style=\"font-size:16px\">Analysis of the pairwise cash-out transaction volume between counterparties. Identification of pairwise counterparties with the highest cash-out transaction volume. Extraction of the corresponding cash-out transactions from the 'PaySim' dataset for an sample based case-by-case verification.</p></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to conduct the analysis, let's aggregate the filtered \"CASH_OUT\" transactions according to the distinct business partner relationships. To create such an multi-column aggregation we will use the `groupby` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners = transactions_cash_out_filtered.groupby(['nameOrig', 'nameDest'])[['amount', 'newbalanceOrig', 'oldbalanceOrg']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now determine the total number of unique business partner relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we identified a total volume of 2,237,358 unique business partner relationships. To gain an even more in depth intuition let's review the first 10 rows of the obtained aggregation result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify business partner relations that correspond to high processed amounts, we will sort the aggregation according to the amount in descending order. Therefore, we will use the `sort_values` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_sorted = transactions_cash_out_partners.sort_values(by=['amount'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now review the top 10 business partner relationships that correspond to the highest transfered amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the distribution of the unique business partner relationship amounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the scatter plot of all cash out posting amounts\n",
    "plt.hist(transactions_cash_out_partners[transactions_cash_out_partners[\"amount\"] > 1000000][\"amount\"], color=\"green\", alpha=0.5, label=\"Cash-Out\", bins=40)\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[Business Partner Relationship Count]\", fontsize=12)\n",
    "plt.xlabel(\"[Transaction Amount]\", fontsize=12)\n",
    "\n",
    "# format y-axis tick labels\n",
    "ax.ticklabel_format(style='plain')\n",
    "\n",
    "# rotate x-axis tick labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# add plot legend\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Distribution of Business Partner Relationship Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a filter to determine all unique business partner relationships that correspond to a total transaction volume **equal or exceeding an amount value of 8 Mio.** in local currency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the amount threshold\n",
    "threshold = 8000000\n",
    "\n",
    "# filter the business partner relationships according to the amount threshold \n",
    "transactions_cash_out_partners_filtered = transactions_cash_out_partners[transactions_cash_out_partners[\"amount\"] > 8000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pivot table and visualize the filtered business partner relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [18, 15] # set the plot figure size\n",
    "\n",
    "# initialize the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create pivot table of business partner relationships\n",
    "pivot = pd.pivot_table(transactions_cash_out_partners_filtered, values='amount', index='nameOrig', columns='nameDest', aggfunc=np.sum, fill_value=0)\n",
    "\n",
    "# plot the pivot table as seaborn heatmap\n",
    "sns.heatmap(pivot, square=False, annot=False, cbar=True, cmap='BuGn_r', alpha=0.8)\n",
    "\n",
    "# add labels of the x- and y-axis\n",
    "plt.ylabel(\"[nameOrig]\", fontsize=12)\n",
    "plt.xlabel(\"[nameDest]\", fontsize=12)\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Pivot Table - Business Partner Relationship Transaction Amounts\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for all \"CASH_OUT\" transactions corresponding to the business partner relationship `nameOrig`: \"C887830623\" and `nameDest`: \"C1319987164\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_A = transactions_cash_out[(transactions_cash_out['nameOrig'] == 'C887830623') & (transactions_cash_out['nameDest'] == 'C1319987164')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of extracted business partner relationship \"CASH_OUT\" transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for all \"CASH_OUT\" transactions corresponding to the business partner relationship `nameOrig`: \"C840795008\" and `nameDest`: \"C1319987164\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_B = transactions_cash_out[(transactions_cash_out['nameOrig'] == 'C840795008') & (transactions_cash_out['nameDest'] == 'C1214752539')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of extracted business partner relationship \"CASH_OUT\" transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenation of the extracted transactions into a single dataframe using the `concat` function of the `Pandas` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_cash_out_partners_all = pd.concat([transactions_cash_out_partners_A, transactions_cash_out_partners_B], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's extract the filtered transactions into an excel spreadsheet for a further sample based testing by the audit team. Therefore, we will in a first step create a time stamp of the data extract for audit trail purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we extract the filtered transactions to excel to the local filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the filename of the excel spreadsheet\n",
    "filename = str(timestamp) + \" - ACA_002_analysis_result_business_partner_amounts.xlsx\"\n",
    "\n",
    "# specify the target data directory of the excel spreadsheet\n",
    "data_directory = os.path.join('./03_results', filename)\n",
    "\n",
    "# extract the filtered transactions to excel\n",
    "transactions_cash_out_partners_all.to_excel(data_directory, header=True, index=False, sheet_name=\"Business_Partner_Amounts\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Assignments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend you to try the following exercises as part of the lab:\n",
    "\n",
    "**1. Analyze the \"TRANSFER\" transactions with regard to transactions with an unusually high amount volume.**\n",
    "\n",
    "> Analyze the 532,909 \"TRANSFER\" transactions extracted during the data validation with regard to transactions with an unusually high amount volume. For this, please follow the procedure presented in chapter 4.1. of the notebook. Extract your analysis results into separate CSV file for a downstream individual case-by-case review, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE SOLUTION HERE\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Analyze the \"TRANSFER\" transactions with regard to relationships between counterparties with an unusually high amount volume.**\n",
    "\n",
    "> Analyze the 532,909 \"TRANSFER\" transactions extracted during the data validation process with regard to relationships between counterparties with an unusually high volume. For this, please follow the procedure presented in chapter 4.2. of the notebook. Extract your analysis results into separate CSV file for a downstream individual case-by-case review, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR CODE SOLUTION HERE\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, a step-by-step introduction to rule-based or \"red-flag\" audit data analysis was presented. In particular, the sub-steps **(1) data import**, **(2) data validation**, **(3) data preparation** and **(4) data analysis** were covered. The structure and analyses presented in this lab can be the starting point for more complex and customized analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to execute the content of your lab outside of the Jupyter notebook environment, e.g. on a compute node or a server. The cell below converts the lab notebook into a standalone and executable python script. Pls. note that to convert the notebook, you need to install Python's `NBConvert` library and its extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the nbconvert library (uncomment the following statements if needed)\n",
    "# !pip3 install nbconvert\n",
    "# !pip3 install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now convert the Jupyter notebook into a plain Python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script aca_lab01.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
