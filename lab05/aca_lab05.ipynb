{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"./assets/logo.png\">\n",
    "\n",
    "##  Lab 05 - Data-Mining Analyseverfahren\n",
    "\n",
    "Lehrgang Internal Auditing, Universität St.Gallen (HSG), 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analysen des Seminars **Audit Data Analytics** basieren auf Jupyter Notebook (https://jupyter.org). Anhand solcher Notebooks ist es möglich eine Vielzahl von Datenanalysen und statistischen Validierungen durchzuführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 700px\" src=\"./assets/banner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im letzten Lab haben Sie die verschiedenen Elemente eines Supervised Deep Learning Workflow kennengelernt z.B. Datenaufbereitung, Modell Training und Modell Validierung. In diesem fünften Lab werden wir Jupyter Notebook verwenden, um ein erstes **Deep Learning basiertes Audit-Analyseverfahren** zu implementieren und anzuwenden.\n",
    "\n",
    "Hierzu werden wir die im Seminar vorgestellten Deep Autoencoder Neural Networks (AENNs) anwenden um Anomalien im Buchungsstoff einer Finanzbuchhaltung zu detektieren. Im Gegensatz zu klassischen Feedforward-Netzen lernen AENNs, die Eingabedaten in eine niedrig-dimensionale Repräsentation zu **enkodieren**.  Gleichzeitig lernt das AENN, die ursprünglichen Daten wieder aus der enkodierten Repräsentation zu **dekodieren**. \n",
    "\n",
    "Die dekodierten Daten, die in der Regel als **Rekonstruktion** bezeichnet werden, sollten eine grosse Ähnlichkeit zu den ursprünglichen **Eingabedaten** aufweisen. Die Buchungssätze, für welche eine erfolgreiche Rekonstruktion nur fehlerhaft gelingt müssen deshalb eine oder mehrere ungewöhnliche Eigenschaften aufweisen. Die nachstehende Abbildung zeigt einen Überblick über den Deep Learning Prozess bzw. die AENN Netzarchitektur, welche wir in diesem Lab implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"./assets/process.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Rahmen des Lab werden wir wieder einige Funktionen der `PyTorch` Bibliothek nutzen, um das AENN zu implementieren und zu trainieren. Im Laufe des Trainingsprozess soll das AENN die charakteristische Eigenschaften historischer **Buchungen** bzw. **Journal Entries** lernen. Nach erfolgreichen Modelltraining, werden wir das Modell anwenden, um anhand des Rekonstruktionsfehlers ungewöhnliche Buchungen innerhalb des Datensatzes zu detektieren. Abschliessend werden wir die gelernten **Repräsentationen** der einzelnen Journaleinträge dazu verwenden, um die erhaltenen Ergebnisse noch aussagekräftiger zu interpretieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei etwaigen Fragen wenden Sie sich, wie immer gerne an uns via **marco (dot) schreyer (at) unisg (dot) ch**. Wir wünschen Ihnen Viel Freude mit unseren Notebooks und Ihren revisorischen Analysen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernziele des Labs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der heutigen Übung sollten Sie in der Lage sein:\n",
    "\n",
    ">1. Die **Grundkonzepte, Funktionsweise und Bestandteile** von Autoencoder Neuronalen Netzen zu verstehen.\n",
    ">2. Eine **Vorverarbeitung** von kategorischen Finanzdaten (d.h. One-Hot Encoding und Min-Max Normalisierung) durchzuführen. \n",
    ">3. Autoencoder Neuronalen Netze anzuwenden, um **Anomalien** in umfangreichen Finanzdaten aufzuspüren.\n",
    ">4. Die **Ergebnisse** bzw. den Rekonstruktionsfehler von Autoencoder Neuronalen Netzen zu interpretieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Einrichten der Analyseumgebung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie in den vorangegangenen Übungen werden wir zunächst eine Reihe von Python-Bibliotheken importieren, welche die Datenanalyse und -visualisierung ermöglichen. In dieser Übung werden wir die Bibliotheken `PyTorch`, `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` und `Seaborn` verwenden. Nachfolgend importieren wir die benötigten Bibliotheken durch die Ausführung der folgenden Anweisungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python data science and utility libraries\n",
    "import os, sys, itertools, urllib, io, warnings\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import der `PyTorch` Deep Learning Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import der `Matplotlib` und `Seaborn` Visualisierungs Bibliotheken und setzen der Visualisierungsparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.rcParams['figure.dpi']= 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausschalten möglicher Warnmeldungen z.B. aufgrund von zukünftigen Änderungen der Bibliotheken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the warning filter flag to ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktivieren der sog. Inline-Darstellung von Visualisierungen in Jupyter-Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen von Unterverzeichnissen innerhalb des aktuellen Arbeitsverzeichnisses für (1) das Speichern der Originaldaten, (2) der Analyseergebnisse und (3) der trainierten Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data sub-directory\n",
    "data_directory = './01_data'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "    \n",
    "# create the results sub-directory\n",
    "results_directory = './02_results'\n",
    "if not os.path.exists(results_directory): os.makedirs(results_directory)\n",
    "\n",
    "# create the models sub-directory\n",
    "models_directory = './03_models'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Festlegen eines zufälligen Seeds zur Gewährleistung der Reproduzierbarkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value); # set pytorch seed cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktivieren des GPU Computing, durch setzen des `device` flag und setzen eines zufälligen `CUDA` Seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cpu or gpu enabled device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
    "\n",
    "# set pytorch gpu seed\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "\n",
    "# log type of device enabled\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] notebook with {} computation enabled'.format(str(now), str(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige der Hardware Informationen zu den ggf. verfügbaren GPU(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzeige der Software Informationen über die verfügbaren `Python` bzw. `PyTorch` Versionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current Python version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The Python version: {}'.format(now, sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current PyTorch version\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] The PyTorch version: {}'.format(now, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenakquise und Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heutzutage beschleunigen Unternehmen die Digitalisierung von Geschäftsprozessen, wovon auch Enterprise Resource Planning (ERP)-Systeme betroffen sind. Diese Systeme sammeln grosse Mengen Daten auf granularer Ebene. Dies gilt insbesondere für die Journalbuchungen einer Organisation, die innerhalb des Hauptbuch und den jeweiligen Nebenbüchern erfasst werden.\n",
    "\n",
    "Die Darstellung in **Abbildung 1** zeigt eine hierarchische Ansicht eines ERP-Systems, das Journalbuchungen in Datenbanktabellen erfasst. Im Kontext revisorischer Prüfungen können die in solchen Systemen erfassten Daten Spuren bzw. wertvolle Hinweise auf mögliche dolose Handlungen enthalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 600px; height: auto\" src=\"./assets/accounting.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abbildung 1:** Hierarchische Ansicht eines Enterprise Resource Planning (ERP)-Systems, das Geschäftsvorfälle auf verschiedene Abstraktionsebenen in Datenbanktabellen erfasst, d.h. auf Ebene (1) des Geschäftsprozesses, (2) der Buchhaltung sowie (3) der Datenbank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden wir den im Rahmen des Labs verwendeten Datensatzes deskriptiv analysieren. Anschliessend werden wir die Daten vorverarbeiten um eine Ausgangslage für das Training eines Neuronalen Netzes zu schaffen. Der Lab Datensatz basiert auf einer angepassten Teilmenge des **\"Synthetic Financial Dataset For Fraud Detection \"** Datensatz von Lopez-Rojas. Der Originaldatensatz wurde ursprünglich über die Kaggle-Plattform für Data Science Wettbewerbe veröffentlicht und kann über den nachfolgenden Link abgerufen werden kann: https://www.kaggle.com/ntnu-testimon/paysim1.\n",
    "\n",
    "In einem ersten Schritt laden wir den Datensatz in unsere Analyseumgebung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into the notebook\n",
    "url = 'https://raw.githubusercontent.com/GitiHubi/courseACA/main/lab05/data/fraud_dataset.csv'\n",
    "ori_dataset = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend prüfen wir die Dimensionalität des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the datasets dimensionalities\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] transactional dataset of {} rows and {} columns retreived.'.format(now, ori_dataset.shape[0], ori_dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darüber hinaus speichern wir eine Sicherheitskopie des geladenen Datensatzes mit aktuellem Zeitstempel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine current timestamp \n",
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# define dataset filename \n",
    "filename = timestamp + \" - original_fraud_dataset.xlsx\"\n",
    "\n",
    "# save dataset extract to the data directory\n",
    "ori_dataset.head(1000).to_excel(os.path.join(data_directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initiales Daten Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz enthält insgesamt **sieben kategorische** und **zwei numerische Attribute**, welche den innerhalb eines SAP FICO Moduls enthaltenen Tabellen BKPF (Buchungsbelegköpfe) und BSEG (Buchungsbelegsegmente) entsprechen. Die nachstehende Liste enthält einen Überblick über die einzelnen Attribute sowie eine kurze Beschreibung ihrer jeweiligen Semantik:\n",
    "\n",
    ">- `BELNR`: die Nummer des Buchhaltungsbelegs,\n",
    ">- `BUKRS`: der Buchungskreis\n",
    ">- `BSCHL`: der Buchungsschlüssel,\n",
    ">- `HKONT`: das gebuchte Hauptbuchkonto,\n",
    ">- `PRCTR`: das gebuchte Profit Center,\n",
    ">- `WAERS`: der Währungsschlüssel,\n",
    ">- `KTOSL`: der Schlüssel des Hauptbuchkontos,\n",
    ">- `DMBTR`: der Betrag in der Hauswährung,\n",
    ">- `WRBTR`: der Betrag in der Belegwährung.\n",
    "\n",
    "Sehen wir uns auch einmal die ersten 10 Zeilen des Datensatzes im Detail an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect top rows of dataset\n",
    "ori_dataset.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vielleicht ist Ihnen bei der Durchsicht der Attribute auch das Attribut mit der Bezeichung `Label` in den Daten aufgefallen. Dieses Attribut enthält die **Ground-Truth Informationen** zu den jeweils einzelnen Buchungen. Das Attribut beschreibt die 'wahre Natur' jeder Transaktion, d.h. ob es sich um eine **reguläre** Transaktion (gekennzeichnet durch `regulär`) oder eine **Anomalie** (gekennzeichnet durch `global` und `lokal`) handelt.  \n",
    "\n",
    "Innerhalb unseres Vorgehens werden wir die Label Information nur dazu verwenden, um die Ergebnisse unserer trainierten Modelle zu validieren. Bitte beachten Sie jedoch, dass uns eine solches Feld in der Realität oftmals nicht zur Verfügung steht. Schauen wir uns nun einmal die Verteilung der regulären gegenüber den anomalen Buchungen im Datensatz an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of anomalies vs. regular transactions\n",
    "ori_dataset.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse zeigt, dass wir es, ähnlich wie in der realen Welt, mit einem **unbalanzierten Datensatz** konfrontiert sind. D.h. insgesamg enthält der Datensatz nur einen sehr kleinen Anteil von **100 (0,109 %)** anomalen Transaktionen. Unter den 100 Anomalien befinden sich **70 (0,076 %)** *globale* Anomalien und **30 (0,003 %)** *lokale* Anomalien. \n",
    "\n",
    "In einem nächsten Schritt entfernen wir das `label` Attribut aus dem Trainingsdatensatz und speichern es in einer gesonderten Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \"ground-truth\" label information for the following steps of the class\n",
    "label = ori_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Vorverarbeitung der Kategorischen Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Sichtung der Daten geht hervor, dass die Mehrzahl der Attribute kategorische (diskrete) Attributwerte aufweisen, z.B. das Buchungsdatum, das Hauptbuchkonto, die Buchungsart und die Währung. Schauen wir uns nun die Verteilung der kategorischen Attribute *Buchungsschlüssel* `BSCHL` sowie *Hauptbuchkonto* `HKONT` einmal im Detail an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to plot posting key and general ledger account side by side\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot the distribution of the posting key attribute\n",
    "plot = sns.countplot(x=ori_dataset['BSCHL'], ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90)\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Buchungsschlüssel Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot the distribution of the general ledger attribute\n",
    "plot = sns.countplot(x=ori_dataset['HKONT'], ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=90)\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Hauptbuchkonto Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Allgemeinen sind Neuronale Netze dafür konzipiert numerische Daten zu verarbeiten. Eine Möglichkeit, diese Anforderung zu erfüllen, ist die Anwendung eines Verfahrens, das als sog. **One-Hot Kodierung** bezeichnet wird. Hierdurch kann eine numerische Darstellung kategorischer Attributwerte abgeleitet werden. Bei der **One-Hot Kodierung** wird für jeden kategorischen Attributwert eine zusätzliche binäre Spalte in den Daten erstellt. \n",
    "\n",
    "Schauen wir uns hierzu das Beispiel in **Abbildung 2** unten an. Das kategorische Attribut **Receiver** in den Orginaldaten enthält die Namen 'Sally', 'John' und 'Emma'. Wir kodieren das Attribut als 'one-hot' Attribut, indem wir eine zusätzliche binäre Spalte für jeden kategorischen Wert in der Spalte 'Receiver' erstellen. Anschliessend kodieren wir z.B. jede Transaktion, die den Wert 'Sally' in der Spalte 'Receiver' aufweist mit dem Wert 1.0 innerhalb der 'Sally' Spalte der Transaktion. Sollte eine Transaktion einen anderen Wert in der Spalte 'Receiver' aufweisen, kodieren wir die 'Sally' Spalte mit dem Wert 0.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 500px; height: auto\" src=\"./assets/encoding.png\">\n",
    "\n",
    "**Abbildung 2:** Beispielhafte 'One-Hot' Kodierung der verschiedenen Receiver Attributwerte in spezifische binäre 'One-Hot' Spalten. Dabei resultiert jeder im Datensatz beobachtbare Attributwert in einer eigene Spalte. Der Spaltenwert **1.0** kodiert das Vorkommen des Attributwertes in der entsprechenden Buchung. Der Spaltenwert **0.0** hingegen zeigt, dass der Attributwert nicht innerhalb der entsprechenden Buchung vorkommt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand dieses Verfahrens können die insgesamt sechs kategorischen Attribute des Datensatzes in numerische Attribute überführt werden. Die `Pandas` Bibliothek stellt hierzu die entsprechende Funktionalität zur Verfügung, welche wir im Nachfolgenden anwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select categorical attributes to be \"one-hot\" encoded\n",
    "categorical_attr_names = ['BUKRS', 'KTOSL', 'PRCTR', 'BSCHL', 'HKONT', 'WAERS']\n",
    "\n",
    "# encode categorical attributes into a binary one-hot encoded representation \n",
    "ori_dataset_cat_processed = pd.get_dummies(ori_dataset[categorical_attr_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend überprüfen wie die vorgenommene **One-Hot Kodierung** anhand der 10 ersten Buchungen des Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect encoded sample transactions\n",
    "ori_dataset_cat_processed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vorverarbeitung der numerischen Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend Analysieren wir nun die Verteilungen der **beiden numerischen Attribute** des Datensatzes. Hierbei handelt es sich um die Attribute (1) *Betrag in Hauswährung* `DMBTR` und (2) *Betrag in Dokumentwährung* `WRBTR` deren jeweilge Verteilungen wir nachfolgend visualisieren: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the log-scaled 'DMBTR' as well as the 'WRBTR' attribute value distribution\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "plot = sns.distplot(ori_dataset['DMBTR'].tolist(), ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Hauswährung - Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "plot = sns.distplot(ori_dataset['WRBTR'].tolist(), ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Dokumentwährung - Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Werte beider Betragsattribute weisen eine jeweils **schiefe** und **steile** Verteilung auf. Wir skalieren deshalb die Werte zunächst logarithmisch. Anschliessend min-max normalisieren wir die Skalierten Werte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the 'DMBTR' and 'WRBTR' attribute\n",
    "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_dataset[numeric_attr_names] + 1e-7\n",
    "\n",
    "# log scale the 'DMBTR' and 'WRBTR' attribute values\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attributes to the range [0,1]\n",
    "ori_dataset_num_processed = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt visualisieren wir die Verteilungen der skalierten bzw. normierten Werte beider Betragsattribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the log-scaled 'DMBTR' as well as the 'WRBTR' attribute value distribution\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "plot = sns.distplot(ori_dataset_num_processed['DMBTR'].tolist(), ax=ax[0])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Hauswährung - Attribute Value Distribution', fontsize=16)\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "plot = sns.distplot(ori_dataset_num_processed['WRBTR'].tolist(), ax=ax[1])\n",
    "\n",
    "# set axis labels\n",
    "plot.set_xlabel('Attribute Value', fontsize=16)\n",
    "plot.set_ylabel('Attribute Value Count', fontsize=16)\n",
    "\n",
    "# set plot title\n",
    "plot.set_title('Betrag in Dokumentwährung - Attribute Value Distribution', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merge Categorical and Numerical Transaction Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschliessend fügen wir die beiden vorverarbeiteten numerischen und kategorischen Attribute zu einem **einzigen Datensatz** zusammen. Der zusammengeführte Datensatz bildet die Grundlage für das nachfolgende Training des Deep Autoencoder Neural Networks (AENNs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_dataset_cat_processed, ori_dataset_num_processed], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werfen wir nun abschliessend noch einen finalen einen Blick auf die Dimensionalität des zusammengefügten Datensatzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect final dimensions of pre-processed transactional data\n",
    "ori_subset_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Abschluss der Vorverarbeitungsschritte verfügen wir über einen Datensatz, der aus einer Gesamtzahl von **91.147 Datensätzen** (Zeilen) und **618 Attributen** (Spalten) besteht. Wir behalten die Anzahl der Spalten im Hinterkopf, da sie die Dimensionalität der Eingabe- und Ausgabeschicht unseres AENNs bestimmen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autoencoder Neural Network Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt möchten wir uns mit der zugrundeliegenden Idee und dem Aufbau eines tiefen **Autoencoder Neural Networks (AENN)** vertraut zu machen. Hierzu werden wir die einzelne Bausteine und die spezifische Netzwerkstruktur von AENNs anhand der `PyTorch` Open-Source-Bibliothek implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Autoencoder Neural Network Architektur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder Neural Networks oder auch **Replicator Neural Networks** sind eine **Unsupervised Learning** Variante der klassischen Feed-Forward Netze. Diese besondere Architektur wurde ursprünglich von Goeffery Hinton und Ruslan Salakhutdinov entwickelt. AENNs bestehen in der Regel aus einer **symmetrischen Netzarchitektur** sowie einer zentralen verborgenen Schicht, die als **latente** oder **engpass Schicht** bezeichnet wird. Diese Schicht weist eine geringere Dimensionalität als die Eingabe- und Ausgabeschicht des Netzwerks auf. Das Lernziel des AENN besteht darin, die ursprünglichen Eingabedaten an der Ausgabeschicht des Netzes möglichst fehlerfrei zu rekonstruieren. **Abbildung 3** zeigt eine schematische Darstellung eines Autoencoder Neural Network's:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 800px; height: auto\" src=\"./assets/autoencoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abbildung 3:** Schematische Darstellung eines Autoencodernetzes, das aus zwei nicht-linearen Abbildungen bzw. Feed-Forward-Netzen besteht. Die beiden miteinander verknüpften Netze werden als Encoder $f_\\theta: \\mathbb{R}^{dx} \\mapsto \\mathbb{R}^{dz}$ und Decoder $g_\\theta: \\mathbb{R}^{dz} \\mapsto \\mathbb{R}^{dx}$ bezeichnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grundsäzlich können AENNs als 'verlustbehaftete' **Komprimierungsalgorithmen** interpretiert werden. Sie sind 'verlustbehaftet' in dem Sinne, dass die rekonstruierten Ausgaben im Vergleich zu den ursprünglichen Eingaben Fehler aufweisen können. Die Differenz zwischen der ursprünglichen Eingabe $x^i$ und ihrer Rekonstruktion $\\hat{x}^i$ wird auch als **Rekonstruktionsfehler** bezeichnet. Im Allgemeinen bestehen AENNs aus drei Hauptbestandteilen:\n",
    "\n",
    "> 1. einem Encoder $f_\\theta$, \n",
    "> 2. einer Decoder $g_\\theta$,\n",
    "> 3. einer Fehlerfunktion $\\mathcal{L_{\\theta}}$.\n",
    "\n",
    "Der Encoder und Decoder bestehen jeweils aus einem klassischen Feedforward Netz mit zu lernenden Parametern $\\theta$. Das **Encodernetz $f_\\theta(\\cdot)$** bildet einen Eingabevektor (z.B. eine Buchung der Finanzbuchhaltung) $x^i$ auf eine komprimierte (d.h. niedrig dimensionale) Repräsentation $z^i$ ab im sog. latenten Raum $Z$ ab. Die niedrig-dimensionale Repräsentation $z^i$ wird anschliessend durch das **Decodernetz** $g_\\theta(\\cdot)$ auf einen Ausgabevektor $\\hat{x}^i$ des ursprünglichen Eingaberaums (z.B. die rekonstruierte Buchung der Finanzbuchhaltung) abgebildet. Formal können die beiden Netze jeweils auch als **nicht-lineare Abbildungen** bzw. Funktion interpretiert werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$f_\\theta(x^i) = s(Wx^i + b)$ &emsp; $f_\\theta: \\mathbb{R}^{dx} \\mapsto \\mathbb{R}^{dz}$,</center>\n",
    "<center>$g_\\theta(z^i) = s′(W′z^i + d)$ &emsp; $g_\\theta: \\mathbb{R}^{dz} \\mapsto \\mathbb{R}^{dx}$,</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wobei die beiden Funktionen die zu lernenden Modellparameter $\\theta = \\{W, b, W', d\\}$ aufweisen. Die Parameter $W \\in \\mathbb{R}^{d_x \\times d_z}, W' \\in \\mathbb{R}^{d_z \\times d_y}$ bezeichnen die Gewichtsmatrizen, die Parameter $b \\in \\mathbb{R}^{dx}$, $d \\in \\mathbb{R}^{dz}$ die Bias-Vektoren der Netze, und $s$ bzw. $s′$ die jeweils nicht-linearen Aktivierungsfunktionen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Autoencoder Neural Network Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt möchten wir nun das Encoder Netz in `PyTorch` implementieren. Der Encoder soll aus insgesamt **neun Schichten** von fully-connected Neuronen bestehen. Darüber hinaus solle der Encoder die nachfolgende Anzahl von Neuronen pro Schicht enthalten: 618-256-128-64-32-16-8-4-3. Die vorhergehende Notation bedeutet, dass die erste Schicht 618 Neuronen umfasst (bestimmt durch die Dimensionalität der Eingabedaten), die zweite Schicht 256 Neuronen und die weiteren Schichten 128, 64, 32, 16, 8, 4 bzw. 3 Neuronen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"middle\" style=\"max-width: 900px; height: auto\" src=\"./assets/neurons.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den nachfolgenden drei Elementen der Implementierung des Encoder Netzes möchten wir eine besonderes Augenmerk schenken:\n",
    "\n",
    ">- `self.encoder_Lx`: definiert die lineare Transformation der jeweiligen Schicht, welche auf die Eingabe angewandt wird: $Wx + b$.\n",
    ">- `nn.init.xavier_uniform`: initialisiert Gewichtsparameter anhand einer gleichmäßigen Xavier Verteilung. \n",
    ">- `self.encoder_Rx`: definiert die nicht-lineare Transformation der jeweiligen Schicht, welche auf die Eingabe angewandt wird: $\\sigma(\\cdot)$.\n",
    "\n",
    "Wir verwenden sog. **Leaky ReLUs**, um saturierende bzw. 'sterbende' Neuronen zu vermeiden und die Trainingskonvergenz zu beschleunigen. Die Anwendung von Leaky ReLUs ermöglicht die Berechnung von Gradienten auch innerhalb des negativen Bereichs einer Aktivierungsfunktion (siehe Schaubild oben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the encoder network\n",
    "class encoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(encoder, self).__init__()\n",
    "\n",
    "        # specify layer 1 - in 618, out 512\n",
    "        self.encoder_L1 = nn.Linear(in_features=ori_subset_transformed.shape[1], out_features=512, bias=True) # add linearity \n",
    "        nn.init.xavier_uniform_(self.encoder_L1.weight) # init weights according to [9]\n",
    "        self.encoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify layer 2 - in 512, out 256\n",
    "        self.encoder_L2 = nn.Linear(512, 256, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L2.weight)\n",
    "        self.encoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 256, out 128\n",
    "        self.encoder_L3 = nn.Linear(256, 128, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L3.weight)\n",
    "        self.encoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 4 - in 128, out 64\n",
    "        self.encoder_L4 = nn.Linear(128, 64, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L4.weight)\n",
    "        self.encoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 5 - in 64, out 32\n",
    "        self.encoder_L5 = nn.Linear(64, 32, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L5.weight)\n",
    "        self.encoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 6 - in 32, out 16\n",
    "        self.encoder_L6 = nn.Linear(32, 16, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L6.weight)\n",
    "        self.encoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 7 - in 16, out 8\n",
    "        self.encoder_L7 = nn.Linear(16, 8, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L7.weight)\n",
    "        self.encoder_R7 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 8 - in 8, out 4\n",
    "        self.encoder_L8 = nn.Linear(8, 4, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L8.weight)\n",
    "        self.encoder_R8 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 9 - in 4, out 3\n",
    "        self.encoder_L9 = nn.Linear(4, 3, bias=True)\n",
    "        nn.init.xavier_uniform_(self.encoder_L9.weight)\n",
    "        self.encoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # define forward pass through the network\n",
    "        x = self.encoder_R1(self.encoder_L1(x))\n",
    "        x = self.encoder_R2(self.encoder_L2(x))\n",
    "        x = self.encoder_R3(self.encoder_L3(x))\n",
    "        x = self.encoder_R4(self.encoder_L4(x))\n",
    "        x = self.encoder_R5(self.encoder_L5(x))\n",
    "        x = self.encoder_R6(self.encoder_L6(x))\n",
    "        x = self.encoder_R7(self.encoder_L7(x))\n",
    "        x = self.encoder_R8(self.encoder_L8(x))\n",
    "        x = self.encoder_R9(self.encoder_L9(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt instanzieren wir ein Modell des Encoder Netzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intstantiate the encoder network model\n",
    "encoder_train = encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend transferieren wir das Encoder Modell auf die `CPU` oder eine ggf. verfügbare `GPU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push model to compute device\n",
    "encoder_train = encoder_train.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sofern verfügbar, prüfen wir ob das Modell erfolgreich auf die `GPU`  übertragen wurde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir die Modellstruktur visualisieren und die Netzarchitektur nochmals durch das Ausführen der folgenden Zelle überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the initialized architectures\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] encoder architecture:\\n\\n{}\\n'.format(now, encoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt vervollständigen wir nun die Autoencoder Architektur durch die Implementierung des entsprechenden Decoder Netzes. Der Decoder soll ebenfall aus insgesamt **neun Schichten** von fully-connected Neuronen bestehen. Zudem soll der Decoder die Architektur des Encoders  **symmetrisch spiegeln**. Wir invertieren hierzu die Ausgestaltung der Schichten des Encoders schichtweise, gemäss der folgenden Struktur 3-4-8-16-32-64-128-256, im Rahmen der Implementierung des Decoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the decoder network\n",
    "class decoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(decoder, self).__init__()\n",
    "\n",
    "        # specify layer 1 - in 3, out 4\n",
    "        self.decoder_L1 = nn.Linear(in_features=3, out_features=4, bias=True) # add linearity \n",
    "        nn.init.xavier_uniform_(self.decoder_L1.weight)  # init weights according to [9]\n",
    "        self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify layer 2 - in 4, out 8\n",
    "        self.decoder_L2 = nn.Linear(4, 8, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L2.weight)\n",
    "        self.decoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 3 - in 8, out 16\n",
    "        self.decoder_L3 = nn.Linear(8, 16, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L3.weight)\n",
    "        self.decoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 4 - in 16, out 32\n",
    "        self.decoder_L4 = nn.Linear(16, 32, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L4.weight)\n",
    "        self.decoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 5 - in 32, out 64\n",
    "        self.decoder_L5 = nn.Linear(32, 64, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L5.weight)\n",
    "        self.decoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 6 - in 64, out 128\n",
    "        self.decoder_L6 = nn.Linear(64, 128, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L6.weight)\n",
    "        self.decoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        # specify layer 7 - in 128, out 256\n",
    "        self.decoder_L7 = nn.Linear(128, 256, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L7.weight)\n",
    "        self.decoder_R7 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 8 - in 256, out 512\n",
    "        self.decoder_L8 = nn.Linear(256, 512, bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L8.weight)\n",
    "        self.decoder_R8 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify layer 9 - in 512, out 618\n",
    "        self.decoder_L9 = nn.Linear(in_features=512, out_features=ori_subset_transformed.shape[1], bias=True)\n",
    "        nn.init.xavier_uniform_(self.decoder_L9.weight)\n",
    "        self.decoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "    \n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # define forward pass through the network\n",
    "        x = self.decoder_R1(self.decoder_L1(x))\n",
    "        x = self.decoder_R2(self.decoder_L2(x))\n",
    "        x = self.decoder_R3(self.decoder_L3(x))\n",
    "        x = self.decoder_R4(self.decoder_L4(x))\n",
    "        x = self.decoder_R5(self.decoder_L5(x))\n",
    "        x = self.decoder_R6(self.decoder_L6(x))\n",
    "        x = self.decoder_R7(self.decoder_L7(x))\n",
    "        x = self.decoder_R8(self.decoder_L8(x))\n",
    "        x = self.decoder_R9(self.decoder_L9(x)) # don't apply dropout to the AE output\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir instanzieren nun auch das Decoder Modell für das `CPU` bzw. `GPU`Training und überzeugen uns davon, dass das Modell erfolgreich initialisiert wurde. Hierzu visualisieren wir wieder die Netzarchitektur durch das Ausführen der nachfolgenden Zelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intstantiate the decoder network model\n",
    "decoder_train = decoder()\n",
    "\n",
    "# push model to compute device\n",
    "decoder_train = decoder_train.to(device)\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] decoder architecture:\\n\\n{}\\n'.format(now, decoder_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschliessend werfen wir noch einen Blick auf die Anzahl der Modellparameter, die wir im Folgenden beabsichtigen zu trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the number of encoder model parameters\n",
    "encoder_num_params = 0\n",
    "\n",
    "# iterate over the distinct encoder parameters\n",
    "for param in encoder_train.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    encoder_num_params += param.numel()\n",
    "\n",
    "# init the number of decoder model parameters\n",
    "decoder_num_params = 0\n",
    "    \n",
    "# iterate over the distinct decoder parameters\n",
    "for param in decoder_train.parameters():\n",
    "\n",
    "    # collect number of parameters\n",
    "    decoder_num_params += param.numel()\n",
    "    \n",
    "# print the number of model paramters\n",
    "now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "print('[LOG {}] number of to be trained AENN model parameters: {}.'.format(now, encoder_num_params + decoder_num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, unser AENN Modell umfasst eine beachtliche Gesamtzahl von **985.021 zu trainierenden Modellparametern**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Autoencoder Neural Network Fehleroptimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach erfolgreicher Instanziierung des AENN Modells möchten wir das Modell nun trainieren. Bevor wir jedoch mit dem Training beginnen, ist es notwendig eine geeignete Fehlerfunktion zu definieren. Zur Erinnerung: Wir wollen unser Modell so trainieren, dass es ein Set von Encoder bzw. Decoder Parametern $\\theta$ lernt, welche die Ähnlichkeit einer gegebenen Buchung $x^{i}$ und ihrer Rekonstruktion $\\hat{x}^{i} = g_\\theta(f_\\theta(x^{i}))$ maximiert. \n",
    "\n",
    "Formal ausgedrückt besteht unser Trainingsziel darin, Parameter $\\theta^*$ zu lernen, für welche gilt $\\arg\\min_{\\theta} \\|X - g_\\theta(f_\\theta(X))\\|$. Um dieses Optimierungsziel zu erreichen, möchten wir mit zunehmenden Training die **Fehlerfunktion** bzw. einen sog. **Rekonstruktionsfehler** $\\mathcal{L_{\\theta}}$ kontinuierlich minimieren. Eine hierfür geeignete Fehlerfunktion findet sich im sog. **Binary-Cross-Entropy (BCE)** Rekonstruktionsfehler, der formal wie nachfolgend definiert ist:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> $\\mathcal{L^{BCE}_{\\theta}}(x^{i};\\hat{x}^{i}) = \\frac{1}{n}\\sum_{i=1}^{n}\\sum_{j=1}^{k} x^{i}_{j} ln(\\hat{x}^{i}_{j}) + (1-x^{i}_{j}) ln(1-\\hat{x}^{i}_{j})$, </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wobei $x^{i}$, $i=1,...,n$ die Menge an Buchungen bezeichnet, $\\hat{x}^{i}$ die jeweiligen Rekonstruktionen und $j=1,...,k$ die verschiedenen Buchungsattribute indexiert. Nachfolgend instanzieren wir die entsprechende BCE Fehlerfunktion der `PyTorch` Bibliothek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend transferieren wir die Berechnung der Fehlerfunktion auf die `CPU` oder eine ggf. verfügbare `GPU`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the optimization criterion / loss function to compute device \n",
    "loss_function = loss_function.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf der Grundlage der Fehlerhöhe eines Mini-Batches an Buchungen berechnet die `PyTorch` Bibliothek automatisiert die Gradienten. Anschliessend werden AENN-Parameter $\\theta$ auf Grundlage der ermittelten Gradienten optimiert. Hierzu ist es lediglich notwendig das gewünschte Optimierungsverfahren in **PyTorch** zu definieren. In der nachfolgenden Notebook Zelle verwenden wir das sog. **Adam Optimierungsverfahren** für die Optimierung der Modellparameter $\\theta$. Darüber hinaus definieren eine Lernrate $l = 0.0001$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "#set the paramete optimization strategy of both networks\n",
    "encoder_optimizer = torch.optim.Adam(encoder_train.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder_train.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir die drei Bausteine des AENN-Modells erfolgreich implementiert und instanziiert haben. Nehmen wir uns Zeit, die Definition der Modelle **Encoder** und **Decoder** sowie des **BCE-Rekonstruktionsfehlers** nochmals zu überprüfen und etwaige Fragen zu besprechen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Autoencoder Neural Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt möchten wir nun ein AENN-Modell anhand der kodierten Transaktionsdaten trainieren. Darüber hinaus werfen wir einen detaillierten Blick auf die einzelnen Trainingshyperparameter und Trainingsschritte sowie den Trainingsfortschritt im Zeitverlauf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Definition der Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginnen wir nun damit, ein AENN Modell für **5 Trainingsepochen** und **128 Buchungen pro Mini-Batch** zu trainieren. Diese Konfiguration der Hyperparameter bedeutet, dass der Datensatz dem AENN ingesamt fünfmal in Mini-Batches von 128 jeweils Buchungen zugeführt wird. Diese Hyperparameter Konfiguration hat zu Folge, dass pro Trainingsepoche **713 Updates** (91.247 Buchungen modulo 128 Buchungen pro Mini-Batch) der AENN Modellparameter erfolgen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training parameters\n",
    "num_epochs = 5 # number of training epochs\n",
    "mini_batch_size = 128 # size of the mini-batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während der Trainingsphase sollen dem AENN Modell kontinuierlich Mini-Batches der gesamten Population von Buchungen zugeführt werden. Hierzu verwenden wir die `DataLoader` Funktionalität der `PyTorch` Bibliothek. Dabei handelt es sich im sog. Iteratoren, welche die Buchungen kontinuierlich in Form von Mini-Batches zur Verfügung stellen. In der nachfolgenden Zelle instanzieren wir einen PyTorch Dataloader der Buchungsdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pre-processed transactional data to PyTorch tensor\n",
    "torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()\n",
    "\n",
    "# push pre-processed transactional data to compute device\n",
    "torch_dataset = torch_dataset.to(device)\n",
    "\n",
    "# init training dataloader\n",
    "train_dataloader = dataloader.DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Hinweis: Durch das Setzen des Parameter `shuffle` werden Mini-Batches in unterschiedlicher Reihenfolge pro Epoche zur Verfügung gestellt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training des Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Definition der Hyperparameter können wir mit dem Training des Modells beginnen. Für jeden zugeführten Mini-Batch werden im Rahmen des Trainingsprozesses die nachfolgenden Schritte ausgeführt: \n",
    "\n",
    ">1. Durchführung des Forwardpass durch das Encoder- und Decoder-Net.\n",
    ">2. Berechnen des BCE-Rekonstruktionsfehlers $\\mathcal{L^{BCE}_{\\theta}}(x^{i};\\hat{x}^{i})$.\n",
    ">3. Durchführung des Backwardpass durch das Decoder- und Encoder-Netz.\n",
    ">4. Update der Encoder $f_\\theta(\\cdot)$- und Decoder $g_\\theta(\\cdot)$ Parameter.\n",
    "\n",
    "Um das Lernen während des Trainings zu gewährleisten, beobachten wir den BCE Rekonstruktionsfehler des AENN-Modells mit fortschreitendem Training. Durch diese Beobachtung ist es möglich auf den Lernfortschritt des Modells zu schliessen. Darüber hinaus kann festgestellt werden, ob bzw. wann der Rekonstruktionsfehler konvergiert.\n",
    "\n",
    "Im Rahmen der Modelloptimierung möchten wir den nachfolgenden `PyTorch`Anweisungen eine besondere Beachtung schenken:\n",
    " \n",
    ">- `reconstruction_loss.backward()` Berechnung die Gradienten auf der Grundlage des Rekonstruktionsfehlers.\n",
    ">- `encoder_optimizer.step()` und `decoder_optimizer.step()` Aktualisierung der Parameter auf Grundlage der Gradienten.\n",
    "\n",
    "Nach jeder abgeschlossenen Trainingsepoche möchten wir zudem einen sog. **Modell Checkpoint** speichern. Die Checkpoints enthalten eine Bestandsaufnahme bzw. 'Schnappschuss' der Modellparameter. Im Allgemeinen ist es eine gute Praxis, während des Trainings solche Checkpoints in regelmässigen Abständen zu speichen. Sollte das Training einmal unterbrochen werden, kann es beginnend auf dem letzten Checkpoint wieder fortgesetzt werden. Für das Speichern eines Modell Checkpoints verwenden wir die nachfolgende `PyTorch` Anweisung:\n",
    "\n",
    ">- `torch.save()`: speichert den Checkpoint der aktuellen Modellparameterwerte auf dem lokalen Dateisystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode (apply dropout when needed)\n",
    "encoder_train.train()\n",
    "decoder_train.train()\n",
    "\n",
    "# init the best loss by setting it to infinity\n",
    "best_loss = np.inf\n",
    "\n",
    "# train autoencoder model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init collection of epoch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # init mini batch counter\n",
    "    mini_batch_count = 0\n",
    "        \n",
    "    # iterate over all mini-batches\n",
    "    for mini_batch_data in train_dataloader:\n",
    "\n",
    "        # increase mini batch counter\n",
    "        mini_batch_count += 1\n",
    "\n",
    "        # push mini batch data to compute device\n",
    "        mini_batch_data = mini_batch_data.to(device)\n",
    "\n",
    "        # =================== (1) forward pass ===================================\n",
    "\n",
    "        # run forward pass\n",
    "        z_representation = encoder_train(mini_batch_data) # encode mini-batch data\n",
    "        mini_batch_reconstruction = decoder_train(z_representation) # decode mini-batch data\n",
    "        \n",
    "        # =================== (2) compute reconstruction loss ====================\n",
    "\n",
    "        # determine reconstruction loss\n",
    "        reconstruction_loss = loss_function(mini_batch_reconstruction, mini_batch_data)\n",
    "        \n",
    "        # =================== (3) backward pass ==================================\n",
    "\n",
    "        # reset graph gradients\n",
    "        decoder_optimizer.zero_grad()\n",
    "        encoder_optimizer.zero_grad()\n",
    "\n",
    "        # run backward pass\n",
    "        reconstruction_loss.backward()\n",
    "        \n",
    "        # =================== (4) update model parameters ========================\n",
    "\n",
    "        # update network parameters\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # =================== monitor training progress ==========================\n",
    "\n",
    "        # print training progress each 1.000 mini-batches\n",
    "        if mini_batch_count % 1000 == 0:\n",
    "            \n",
    "            # print mini batch reconstuction results\n",
    "            now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "            print('[LOG {}] epoch: [{}/{}], batch: {}, batch-train-loss: {}'.format(str(now), str(epoch+1), str(num_epochs), str(mini_batch_count), str(np.round(reconstruction_loss.item(), 8))))\n",
    "            \n",
    "        # collect mini-batch loss\n",
    "        train_mini_batch_losses.extend([reconstruction_loss.item()])\n",
    "\n",
    "    # =================== evaluate model performance =============================\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "                                 \n",
    "    # print training epoch results\n",
    "    now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: [{}/{}], epoch-train-loss: {}'.format(str(now), str(epoch+1), str(num_epochs), str(np.round(train_epoch_loss, 8))))\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # =================== save model snapshot to disk ============================\n",
    "    \n",
    "    # case: new best model trained\n",
    "    if train_epoch_loss < best_loss:\n",
    "    \n",
    "        # save trained encoder model file to disk\n",
    "        encoder_model_name = \"ep_{}_encoder_model.pth\".format((epoch+1))\n",
    "        torch.save(encoder_train.state_dict(), os.path.join(models_directory, encoder_model_name))\n",
    "\n",
    "        # save trained decoder model file to disk\n",
    "        decoder_model_name = \"ep_{}_decoder_model.pth\".format((epoch+1))\n",
    "        torch.save(decoder_train.state_dict(), os.path.join(models_directory, decoder_model_name))\n",
    "        \n",
    "        # update best loss\n",
    "        best_loss = train_epoch_loss\n",
    "\n",
    "        # print epoch loss\n",
    "        now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "        print('[LOG {}] epoch: [{}/{}], new best epoch-train-loss: {} found'.format(str(now), str(epoch+1), str(num_epochs), str(np.round(train_epoch_loss, 8))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt visualisieren wir den jeweiligen Rekonstruktionsfehler für jede Trainingsepoche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figwidth(18)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' prediction error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"[Training Epoch $e_i$]\", fontsize=14)\n",
    "ax.set_ylabel(\"[Reconstruction Error $\\mathcal{L}^{BCE}$]\", fontsize=14)\n",
    "\n",
    "# set plot legend\n",
    "plt.legend(loc=\"upper right\", numpoints=1, fancybox=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title('Training Epochs $e_i$ vs. Reconstruction Error $L^{BCE}$', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu beobachten, dass der Rekonstruktionsfehler des AENN Models nach fünf Epochen kontinuierlich zu sinken beginnt. Diese Beobachtung impliziert, dass es dem Modell sukzessive gelingt die innerhalb des Datensatzes enthaltenen Buchungen zu rekonstruieren. Anhand der Visualisierung wird jedoch auch deutlich, dass das Modell noch einige Epochen weiter trainiert werden könnte bis der Rekonstruktionsfehler nicht mehr sinkt bzw. konvergiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Autoencoder Neural Network Modell Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Abschnitt möchten wir die Fähigkeit des erlernten AENN Modells zur Erkennung von Anomalien in Buchhaltungsdaten evaluieren. Hierzu werden wir auf vortrainierte AENN Modelle zurück greifen. Die Evaluation umfasst die **lokalen** als auch die **globalen** Anomalien des Datensatzes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Laden eines Modell Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Evaluation laden wir üblicherweise das AAENN-Modell mit **geringstem Rekonstruktions- bzw. Diskriminationsfehler**. Pro Trainingsepoche wurde im Rahmen des Modelltrainings jeweils ein Checkpoint der Modellparameter innerhalb des lokalen Modellverzeichnis gespeichert. Wir werden nun die bereits für **30 Trainingsepochen** trainierten Modell Checkpoint laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore pretrained model checkpoint\n",
    "encoder_model_name = 'https://raw.githubusercontent.com/GitiHubi/courseACA/main/lab05/models/ep_30_encoder_model_small.pth'\n",
    "decoder_model_name = 'https://raw.githubusercontent.com/GitiHubi/courseACA/main/lab05/models/ep_30_decoder_model_small.pth'\n",
    "\n",
    "# read stored model from the remote location\n",
    "encoder_bytes = urllib.request.urlopen(encoder_model_name)\n",
    "decoder_bytes = urllib.request.urlopen(decoder_model_name)\n",
    "\n",
    "# load tensor from io.BytesIO object\n",
    "encoder_buffer = io.BytesIO(encoder_bytes.read())\n",
    "decoder_buffer = io.BytesIO(decoder_bytes.read())\n",
    "\n",
    "# init evaluation encoder and decoder model\n",
    "encoder_eval = encoder()\n",
    "decoder_eval = decoder()\n",
    "\n",
    "# push encoder and decoder model to compute device\n",
    "encoder_eval = encoder_train.to(device)\n",
    "decoder_eval = decoder_train.to(device)\n",
    "\n",
    "# load trained models\n",
    "encoder_eval.load_state_dict(torch.load(encoder_buffer, map_location=lambda storage, loc: storage))\n",
    "decoder_eval.load_state_dict(torch.load(decoder_buffer, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Evaluation des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach erfolgreichem Laden des Modell Checkpoints transferieren wir das Modell für Evaluierungszwecke auf die `CPU` (Hinweis: Dies ermöglicht uns die Rekonstruktionsfehler aller Buchungen ohne etwaige Limitierungen durch den Arbeitsspeicher der `GPU` zu berechnen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set networks in evaluation mode (don't apply dropout)\n",
    "encoder_eval.eval()\n",
    "decoder_eval.eval()\n",
    "\n",
    "# push encoder and decoder model to compute device\n",
    "encoder_eval = encoder_eval.to('cpu')\n",
    "decoder_eval = decoder_eval.to('cpu')\n",
    "\n",
    "# push the dataset to the CPU \n",
    "torch_dataset = torch_dataset.to('cpu')\n",
    "\n",
    "# push the loss function to the CPU\n",
    "loss_function = loss_function.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt berechnen wir die individuellen **BCE Rekonstruktionsfehler** für jede Buchung $x_{i}$ innerhalb des Datensatzes. Zu diesem Zweck wird zunächst die Rekonstruktion $\\hat{x}_{i}$ jeder Buchung ermittelt. Im Anschluss wird der **BCE Rekonstruktionsfehler** der rekonstruierten Buchung $\\hat{x}_{i}$ durch Vergleich mit der originalen Buchungen $x_{i}$ des Datensatzes berechnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct encoded transactional data\n",
    "reconstruction = decoder_eval(encoder_eval(torch_dataset))\n",
    "\n",
    "# init binary cross entropy errors\n",
    "reconstruction_loss_transaction = np.zeros(reconstruction.size()[0])\n",
    "\n",
    "# iterate over all detailed reconstructions\n",
    "for i in range(0, reconstruction.size()[0]):\n",
    "\n",
    "    # determine reconstruction loss - individual transactions\n",
    "    reconstruction_loss_transaction[i] = loss_function(reconstruction[i], torch_dataset[i]).item()\n",
    "\n",
    "    if(i % 10000 == 0):\n",
    "\n",
    "        ### print conversion summary\n",
    "        now = dt.datetime.utcnow().strftime(\"%Y.%m.%d-%H:%M:%S\")\n",
    "        print('[LOG {}] collected individual reconstruction loss of: {:06}/{:06} transactions'.format(now, i, reconstruction.size()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach Berechnung der individuellen Rekonstruktionsfeheler visualiseren wir die Höhe des jeweils berechneten Fehlers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# set plot size\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "# assign unique id to transactions\n",
    "plot_data = np.column_stack((np.arange(len(reconstruction_loss_transaction)), reconstruction_loss_transaction))\n",
    "\n",
    "# obtain regular transactions as well as global and local anomalies\n",
    "regular_data = plot_data[label == 'regular']\n",
    "global_outliers = plot_data[label == 'global']\n",
    "local_outliers = plot_data[label == 'local']\n",
    "\n",
    "# plot reconstruction error scatter plot\n",
    "ax.scatter(regular_data[:, 0], regular_data[:, 1], c='C0', alpha=0.4, marker=\"o\", s=30, label='regular') # plot regular transactions\n",
    "ax.scatter(global_outliers[:, 0], global_outliers[:, 1], c='C1', marker=\"^\", s=80, label='global') # plot global outliers\n",
    "ax.scatter(local_outliers[:, 0], local_outliers[:, 1], c='C2', marker=\"*\", s=80, label='local') # plot local outliers\n",
    "\n",
    "# add plot legend of transaction classes\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel(\"[Journal Entry ID $x_i$]\", fontsize=14)\n",
    "ax.set_ylabel(\"[Reconstruction Error $\\mathcal{L}^{BCE}$]\", fontsize=14)\n",
    "\n",
    "# add plot title\n",
    "plt.title('Journal Entry ID $x_i$ vs. Reconstruction Error $L^{BCE}$', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Visualisierung zeigt, dass das unser AENN Modell die meisten regulären Buchungen mit geringem Fehler rekonstruieren kann. Prallel weisen die **globalen Anomalien (grün)** als auch **lokalen Anomalien (rot)** einen Vergleichsweise hohen Rekonstruktionsfehler auf. Auf Grundlage dieses Analyseergebnis lässt sich konstatieren, dass es Anhand der Rekonstruktionsfehler möglich ist, **Anomalien (grün und rot)** von den regulären Buchungen (blau) des Buchungsstoffes zu unterscheiden.\n",
    "\n",
    "Um diese Feststellung weiter zu untersuchen wollen wir nun die Buchungen, die einen **Rekonstruktionsfehler >= 0.12** aufweisen aus dem Datensatz filtern. Darüber hinaus nehmen wir (wie oben dargestellt) an, dass diese Buchungen den **globalen Anomalien** des Buchungsstoffes entsprechen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append labels to original dataset\n",
    "ori_dataset['label'] = label\n",
    "\n",
    "# extract transactions exhibiting a reconstruction error >= 0.12\n",
    "autoencoder_global_anomalies = ori_dataset[reconstruction_loss_transaction >= 0.12]\n",
    "\n",
    "# inspect transactions exhibiting a reconstruction error >= 0.12\n",
    "autoencoder_global_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns die nun die Buchungen in eine Excel-Tabelle extrahieren, um diese dem Prüfungsteam zur Verfügung zu stellen. Hierzu werden wir in einem ersten Schritt einen Zeitstempel des Datenextrakts für den Audit-Trail der Prüfung generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend extrahieren wir die gefilterten **globalen Anomalien** als Excel-Datei zur weiteren substantiellen Prüfung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the filename of the excel spreadsheet\n",
    "filename = str(timestamp) + \" - ACA_001_autoencoder_global_anomalies.xlsx\"\n",
    "\n",
    "# specify the target data directory of the excel spreadsheet\n",
    "data_directory = os.path.join(results_directory, filename)\n",
    "\n",
    "# extract the filtered transactions to excel\n",
    "autoencoder_global_anomalies.to_excel(data_directory, header=True, index=False, sheet_name=\"Global_Anomalies\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns nun auch die Buchungen genauer an, die einen **Rekonstruktionsfehler >= 0.04 jedoch =< 0.12** aufweisen. Hierbei nehmen wir (wie oben dargestellt) an, dass diese Buchungen **lokalen Anomalien** des Buchungsstoffes entsprechen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract transactions exhibiting a reconstruction error < 0.12 and >= 0.04\n",
    "autoencoder_local_anomalies = ori_dataset[(reconstruction_loss_transaction >= 0.04) & (reconstruction_loss_transaction < 0.12)]\n",
    "\n",
    "# inspect transactions exhibiting a reconstruction error < 0.12 and >= 0.04\n",
    "autoencoder_local_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns die gefilterten Transaktionen erneut in eine Excel-Tabelle extrahieren, um sie dem Prüfungsteam zur Verfügung zu stellen. Hierzu werden wir zunächst wieder einen Zeitstempel des Datenextrakts für den Audit-Trail der Prüfung generieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend extrahieren wir die gefilterten **lokalen Anomalien** als Excel-Datei zur weiteren substantiellen Prüfung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the filename of the excel spreadsheet\n",
    "filename = str(timestamp) + \" - ACA_002_autoencoder_local_anomalies.xlsx\"\n",
    "\n",
    "# specify the target data directory of the excel spreadsheet\n",
    "data_directory = os.path.join(results_directory, filename)\n",
    "\n",
    "# extract the filtered transactions to excel\n",
    "autoencoder_local_anomalies.to_excel(data_directory, header=True, index=False, sheet_name=\"Local_Anomalies\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation der Buchungsstoff Repräsentationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im realen Prüfungskontext ist es in der Regel von Vorteil, zusätzlich zur Höhe des Rekonstruktionsfehlers die durch das AENN-Modell **erlernten Repräsentationen** der Buchungen zu untersuchen. Eine solche Untersuchung ermöglicht es Rückschlüsse über die **strukturelle Semantik** des Buchungsstoffes und der Buchungsattribute zu ziehen. Darüber hinaus bietet die Analyse die Möglichkeit evtl. ermittelte Anomalien in den Gesamtkontext des Buchungstoffes einzordnen\n",
    "\n",
    "Um die Repräsentation der Buchungen zu erhalten führen wir für jede Buchung einen Forwardpass durch den Encoder des AENN Modells durch. Hierzu laden wir einen bereits für **80 Epochen trainierten Model Checkpoint** des Encoder Netzes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore pretrained model checkpoint\n",
    "encoder_model_name = 'https://raw.githubusercontent.com/GitiHubi/courseACA/main/lab05/models/ep_80_encoder_model_small.pth'\n",
    "\n",
    "# read stored model from the remote location\n",
    "encoder_bytes = urllib.request.urlopen(encoder_model_name)\n",
    "\n",
    "# load tensor from io.BytesIO object\n",
    "encoder_buffer = io.BytesIO(encoder_bytes.read())\n",
    "\n",
    "# init evaluation encoder and decoder model\n",
    "encoder_eval = encoder()\n",
    "\n",
    "# push encoder and decoder model to compute device\n",
    "encoder_eval = encoder_eval.to('cpu')\n",
    "\n",
    "# load trained models\n",
    "encoder_eval.load_state_dict(torch.load(encoder_buffer, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem nächsten Schritt führen wir für jede Buchung einen Forwardpass durch das AENN Modell durch. Um Ergebnis erhalten wir somit die drei-dimensionale Repräsentation jeder Buchung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the dataset to the CPU \n",
    "torch_dataset = torch_dataset.to('cpu')\n",
    "\n",
    "# run forward path through encoder to obtain journal entry representations\n",
    "entry_representations = encoder_eval(torch_dataset)\n",
    "\n",
    "# convert the representations to a pandas dataframe\n",
    "entry_representation = pd.DataFrame(entry_representations.data.cpu().numpy(), columns=['z1', 'z2', 'z3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschliessend versehen wir, für Validierungs- und Visualierungszwecke, die Repräsentationen mit den ursprünglichen Labeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_representation['label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vor der Visualisierung werfen wir noch einen prüfenden Blick auf die erhaltenen Koordinaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_representation.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund des drei-dimensionalen **Latenten Raums** können wir den Raum und die Repräsentationen mit Hilfe der `Matplotlib` 3D-Funktionalität zu visualisieren. Innerhalb der nachfolgenden Zelle erstellen wir eine Visualisierung dieses Raums samt Repräsentationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enforce inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# import 3d plotting and animation libraries\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "# init the plot\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# change plot perspective\n",
    "ax.view_init(elev=30, azim=240)\n",
    "\n",
    "# set axis paramaters of subplot\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot regular transactions, just the first 1000 to gain an intuition\n",
    "regular = entry_representation[entry_representation['label'] == 'regular']\n",
    "ax.scatter(regular['z1'][0:2000], regular['z2'][0:2000], regular['z3'][0:2000], c='C0', alpha=0.4, marker=\"o\", label='regular')\n",
    "\n",
    "# plot first order anomalous transactions\n",
    "global_anomalies = entry_representation[entry_representation['label'] == 'global']\n",
    "ax.scatter(global_anomalies['z1'], global_anomalies['z2'], global_anomalies['z3'], c='C1', s=100, marker=\"^\", label='global')\n",
    "\n",
    "# plot second order anomalous transactions\n",
    "local_anomalies = entry_representation[entry_representation['label'] == 'local']\n",
    "ax.scatter(local_anomalies['z1'], local_anomalies['z2'], local_anomalies['z3'], c='C2', s=100, marker=\"*\", label='local')\n",
    "\n",
    "# set axis labels\n",
    "ax.set_xlabel('activation [$z_1$]', weight='normal', fontsize=12)\n",
    "ax.set_ylabel('activation [$z_2$]', weight='normal', fontsize=12)\n",
    "ax.set_zlabel('activation [$z_3$]', weight='normal', fontsize=12)\n",
    "\n",
    "# add plot legend of transaction classes\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# set plot title\n",
    "plt.title('AENN Model Latent Space', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Aufgaben:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Ihr wissen zu vertiefen empfehlen wir, die nachfolgenden Übungen zu bearbeiten:\n",
    "\n",
    "**1. Trainieren und evaluieren Sie ein Autoencoder Neural Network model mit reduziertem Bottleneck.**\n",
    "\n",
    "> Die innerhalb des Notebooks vorgestellte Architektur führte zu einem guten Modell für die Erkennung von Anomalien. Prüfen Sie wie sich die Performance verändert, wenn die Dimensionalität der **Bottleneck Schicht** reduziert wird. Reduzieren Sie hierzu die Anzahl der Neuronen innerhalb des Encoder bzw. Decoder Bottlenecks auf zwei Neuronen. Wie ändert sich die Fähigkeit des Modells Anomalien im Buchungsstoff zu erkennen? Lassen sich unterschiedliche Aussagen für globale bzw. lokale Anomalien treffen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Trainieren und evaluieren Sie ein `shallow` Autoencoder Neural Network model.**\n",
    "\n",
    "> Die innerhalb des Notebooks vorgestellte Architektur führte zu einem guten Modell für die Erkennung von Anomalien. Prüfen Sie wie sich die Performance verändert, wenn **mehrere der versteckten Schichten** entfernt werden. Passen Sie hierzu die Implementierungen des Encoders und Decoders entsprechend an. Wie ändert sich die Fähigkeit des Modells Anomalien im Buchungsstoff zu erkennen? Lassen sich unterschiedliche Aussagen für globale bzw. lokale Anomalien treffen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# Sie können Ihre Lösung an dieser Stelle einfügen\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Notebook umfasste eine schrittweise Einführung in **Entwurf, Implementierung, Training und Bewertung** eines auf einem neuronalen Netz basierenden Ansatzes zur Erkennung von Anomalien in Buchhaltungsdaten. Die vorgestellten Code Beispiele und die Übungen können als Ausgangspunkt für für die Entwicklung und das Testen komplexerer Strategien zur Erkennung von Anomalien dienen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
